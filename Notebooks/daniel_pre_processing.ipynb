{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38257243",
   "metadata": {},
   "source": [
    "# Daniel's Pre-Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423eb4d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Daniel's Branch Created\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24fff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d41667",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('../Dataset/train.json')\n",
    "test_df = pd.read_json('../Dataset/test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6793498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pluto rotates once on its axis every 6.39 Eart...</td>\n",
       "      <td>Earth rotates on its axis once times in one day.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---Glenn =====================================...</td>\n",
       "      <td>Earth rotates on its axis once times in one day.</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>geysers - periodic gush of hot water at the su...</td>\n",
       "      <td>The surface of the sun is much hotter than alm...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Facts: Liquid water droplets can be changed in...</td>\n",
       "      <td>Evaporation is responsible for changing liquid...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>By comparison, the earth rotates on its axis o...</td>\n",
       "      <td>Earth rotates on its axis once times in one day.</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0  Pluto rotates once on its axis every 6.39 Eart...   \n",
       "1  ---Glenn =====================================...   \n",
       "2  geysers - periodic gush of hot water at the su...   \n",
       "3  Facts: Liquid water droplets can be changed in...   \n",
       "4  By comparison, the earth rotates on its axis o...   \n",
       "\n",
       "                                          hypothesis    label  \n",
       "0   Earth rotates on its axis once times in one day.  neutral  \n",
       "1   Earth rotates on its axis once times in one day.  entails  \n",
       "2  The surface of the sun is much hotter than alm...  neutral  \n",
       "3  Evaporation is responsible for changing liquid...  entails  \n",
       "4   Earth rotates on its axis once times in one day.  entails  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b8d239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23083</th>\n",
       "      <td>which is not only the motion of our bodies, bu...</td>\n",
       "      <td>Work is done only if a force is exerted in the...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23084</th>\n",
       "      <td>The Red Star, that celestial curse whose eccen...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23085</th>\n",
       "      <td>The lines in the spectrum of a luminous body s...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23086</th>\n",
       "      <td>The radial velocity of a star away from or tow...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23087</th>\n",
       "      <td>This expansion causes the light from distant s...</td>\n",
       "      <td>Red-shift refers to a shift toward red in the ...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 premise  \\\n",
       "23083  which is not only the motion of our bodies, bu...   \n",
       "23084  The Red Star, that celestial curse whose eccen...   \n",
       "23085  The lines in the spectrum of a luminous body s...   \n",
       "23086  The radial velocity of a star away from or tow...   \n",
       "23087  This expansion causes the light from distant s...   \n",
       "\n",
       "                                              hypothesis    label  \n",
       "23083  Work is done only if a force is exerted in the...  neutral  \n",
       "23084  Red-shift refers to a shift toward red in the ...  neutral  \n",
       "23085  Red-shift refers to a shift toward red in the ...  entails  \n",
       "23086  Red-shift refers to a shift toward red in the ...  entails  \n",
       "23087  Red-shift refers to a shift toward red in the ...  entails  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e37ae",
   "metadata": {},
   "source": [
    "# Data Pre-Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917129ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DCCN9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DCCN9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "if not nltk.download('punkt'):\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('punkt_tab')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "if not nltk.download('stopwords'):\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a91b88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just common English contractions. We used it in Lab 5 before!\n",
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
    "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
    "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
    "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n",
    "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
    "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\",\n",
    "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
    "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
    "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
    "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
    "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
    "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
    "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
    "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\",\n",
    "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n",
    "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
    "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
    "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94ade6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DCCN9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Stemmer and Lemmatizer\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "if not nltk.download('wordnet'):\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('omw-1.4')\n",
    "    nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6b71d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for lemmatization with POS tagging\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # Default to noun if no match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3309d028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allowed POS tags for filtering (example: nouns, verbs, adjectives, adverbs)\n",
    "allowed_pos_tags = {'NN', 'NNS', 'NNP', 'NNPS',   # Nouns\n",
    "                    'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',  # Verbs\n",
    "                    'JJ', 'JJR', 'JJS',           # Adjectives\n",
    "                    'RB', 'RBR', 'RBS'}           # Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec143704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the desired POS tags\n",
    "def filter_tokens_by_pos(tokens):\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    filtered = [word for word, tag in tagged_tokens if tag in allowed_pos_tags]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ae31e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "min_word_length = 3\n",
    "max_word_length = 60 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97386b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset, min_word_length=3, max_word_length=50, method='none', pos_filter=False, stop_w=False):\n",
    "    cleaned_premises = []\n",
    "    cleaned_hypotheses = []\n",
    "    cleaned_labels = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        premise = row['premise']\n",
    "        hypothesis = row['hypothesis']\n",
    "        label = row['label']\n",
    "\n",
    "        # Lowercase\n",
    "        premise = premise.lower()\n",
    "        hypothesis = hypothesis.lower()\n",
    "\n",
    "        # Expand contractions\n",
    "        for contraction, full_form in contraction_dict.items():\n",
    "            premise = premise.replace(contraction, full_form)\n",
    "            hypothesis = hypothesis.replace(contraction, full_form)\n",
    "\n",
    "        # Remove punctuation/special chars\n",
    "        premise = re.sub(r'[^\\w\\s]', '', premise)\n",
    "        hypothesis = re.sub(r'[^\\w\\s]', '', hypothesis)\n",
    "\n",
    "        # Normalize whitespace\n",
    "        premise = re.sub(r'\\s+', ' ', premise).strip()\n",
    "        hypothesis = re.sub(r'\\s+', ' ', hypothesis).strip()\n",
    "\n",
    "        # Tokenization\n",
    "        premise_tokens = word_tokenize(premise)\n",
    "        hypothesis_tokens = word_tokenize(hypothesis)\n",
    "\n",
    "        # Stemming/Lemmatization\n",
    "        if method == 'stem':\n",
    "            stemmer = PorterStemmer()\n",
    "            premise_tokens = [stemmer.stem(word) for word in premise_tokens]\n",
    "            hypothesis_tokens = [stemmer.stem(word) for word in hypothesis_tokens]\n",
    "        elif method == 'lemmatize':\n",
    "            lemmatizer = WordNetLemmatizer()\n",
    "            premise_pos_tags = pos_tag(premise_tokens)\n",
    "            hypothesis_pos_tags = pos_tag(hypothesis_tokens)\n",
    "            premise_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in premise_pos_tags]\n",
    "            hypothesis_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in hypothesis_pos_tags]\n",
    "\n",
    "        # POS Filtering\n",
    "        if pos_filter:\n",
    "            premise_tokens = filter_tokens_by_pos(premise_tokens)\n",
    "            hypothesis_tokens = filter_tokens_by_pos(hypothesis_tokens)\n",
    "\n",
    "        # Remove stop words\n",
    "        if stop_w:\n",
    "            premise_tokens = [word for word in premise_tokens if word not in stop_words]\n",
    "            hypothesis_tokens = [word for word in hypothesis_tokens if word not in stop_words]\n",
    "\n",
    "        # Now check token length AFTER cleaning\n",
    "        if (min_word_length <= len(premise_tokens) <= max_word_length and\n",
    "            min_word_length <= len(hypothesis_tokens) <= max_word_length):\n",
    "            cleaned_premises.append(premise_tokens)\n",
    "            cleaned_hypotheses.append(hypothesis_tokens)\n",
    "            cleaned_labels.append(label)\n",
    "        # else: skip row\n",
    "\n",
    "    # Build DataFrame from all cleaned token lists\n",
    "    new_dataset = pd.DataFrame({\n",
    "        'premise': cleaned_premises,\n",
    "        'hypothesis': cleaned_hypotheses,\n",
    "        'label': cleaned_labels\n",
    "    })\n",
    "\n",
    "    return new_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "810a3997",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_dataset = clean_dataset(train_df, stop_w=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3779c637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premise</th>\n",
       "      <th>hypothesis</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[pluto, rotates, axis, every, 639, earth, days]</td>\n",
       "      <td>[earth, rotates, axis, times, one, day]</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[glenn, per, day, earth, rotates, axis]</td>\n",
       "      <td>[earth, rotates, axis, times, one, day]</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[geysers, periodic, gush, hot, water, surface,...</td>\n",
       "      <td>[surface, sun, much, hotter, almost, anything,...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[facts, liquid, water, droplets, changed, invi...</td>\n",
       "      <td>[evaporation, responsible, changing, liquid, w...</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[comparison, earth, rotates, axis, per, day, r...</td>\n",
       "      <td>[earth, rotates, axis, times, one, day]</td>\n",
       "      <td>entails</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             premise  \\\n",
       "0    [pluto, rotates, axis, every, 639, earth, days]   \n",
       "1            [glenn, per, day, earth, rotates, axis]   \n",
       "2  [geysers, periodic, gush, hot, water, surface,...   \n",
       "3  [facts, liquid, water, droplets, changed, invi...   \n",
       "4  [comparison, earth, rotates, axis, per, day, r...   \n",
       "\n",
       "                                          hypothesis    label  \n",
       "0            [earth, rotates, axis, times, one, day]  neutral  \n",
       "1            [earth, rotates, axis, times, one, day]  entails  \n",
       "2  [surface, sun, much, hotter, almost, anything,...  neutral  \n",
       "3  [evaporation, responsible, changing, liquid, w...  entails  \n",
       "4            [earth, rotates, axis, times, one, day]  entails  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f86f3c4",
   "metadata": {},
   "source": [
    "## Build dictionary of words and word2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e95f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_train_dataset['premise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d42bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique words: 21790\n"
     ]
    }
   ],
   "source": [
    "# Create a unique word list from the cleaned dataset\n",
    "unique_words = set()\n",
    "for sentence in clean_train_dataset['premise']:\n",
    "    for word in sentence:\n",
    "        unique_words.add(word)\n",
    "\n",
    "print(f\"Count of unique words: {len(unique_words)}\")\n",
    "#No lemmatization or stemming count = 22555\n",
    "#Lemmatization count = 18986\n",
    "#Stemming count = 15954\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "73c6c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_list = sorted(list(unique_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "759cdfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No. of words with each method.\n",
    "\n",
    "word2id = {w:i for i,w in enumerate(unique_words_list)}\n",
    "id2word = {i:w for i,w in enumerate(unique_words_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d197013e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 0,\n",
       " '000': 1,\n",
       " '000010m': 2,\n",
       " '0001': 3,\n",
       " '000338324205530': 4,\n",
       " '004': 5,\n",
       " '0055': 6,\n",
       " '0075ml': 7,\n",
       " '01': 8,\n",
       " '010': 9,\n",
       " '0104': 10,\n",
       " '010508': 11,\n",
       " '012': 12,\n",
       " '014': 13,\n",
       " '0147this': 14,\n",
       " '016': 15,\n",
       " '02': 16,\n",
       " '02cm2': 17,\n",
       " '03': 18,\n",
       " '04': 19,\n",
       " '0405060708': 20,\n",
       " '04622quot': 21,\n",
       " '05': 22,\n",
       " '05c': 23,\n",
       " '05v': 24,\n",
       " '06': 25,\n",
       " '060721': 26,\n",
       " '07': 27,\n",
       " '070b': 28,\n",
       " '075': 29,\n",
       " '092': 30,\n",
       " '093': 31,\n",
       " '1': 32,\n",
       " '10': 33,\n",
       " '100': 34,\n",
       " '1000': 35,\n",
       " '100000': 36,\n",
       " '10000000': 37,\n",
       " '1000000000000000': 38,\n",
       " '100000th': 39,\n",
       " '10001500': 40,\n",
       " '10002000': 41,\n",
       " '1001': 42,\n",
       " '10020': 43,\n",
       " '100fold': 44,\n",
       " '100ml': 45,\n",
       " '100um': 46,\n",
       " '101': 47,\n",
       " '101325': 48,\n",
       " '102': 49,\n",
       " '1020': 50,\n",
       " '1023': 51,\n",
       " '103': 52,\n",
       " '1033': 53,\n",
       " '104': 54,\n",
       " '1040': 55,\n",
       " '105': 56,\n",
       " '106': 57,\n",
       " '1069': 58,\n",
       " '107': 59,\n",
       " '107607676383': 60,\n",
       " '109': 61,\n",
       " '1093': 62,\n",
       " '10e4': 63,\n",
       " '11': 64,\n",
       " '110': 65,\n",
       " '1104': 66,\n",
       " '1107': 67,\n",
       " '111': 68,\n",
       " '1117': 69,\n",
       " '113': 70,\n",
       " '113000': 71,\n",
       " '11313': 72,\n",
       " '115': 73,\n",
       " '1152': 74,\n",
       " '116': 75,\n",
       " '116page': 76,\n",
       " '1170': 77,\n",
       " '117618': 78,\n",
       " '118': 79,\n",
       " '11976': 80,\n",
       " '11b': 81,\n",
       " '11billionyearold': 82,\n",
       " '11year': 83,\n",
       " '12': 84,\n",
       " '120': 85,\n",
       " '1200': 86,\n",
       " '1200calorie': 87,\n",
       " '120mm': 88,\n",
       " '121': 89,\n",
       " '1212': 90,\n",
       " '1215': 91,\n",
       " '1216': 92,\n",
       " '1219': 93,\n",
       " '122': 94,\n",
       " '1221': 95,\n",
       " '12282': 96,\n",
       " '1229': 97,\n",
       " '123': 98,\n",
       " '1235': 99,\n",
       " '123v': 100,\n",
       " '125': 101,\n",
       " '125126': 102,\n",
       " '128': 103,\n",
       " '12c': 104,\n",
       " '12month': 105,\n",
       " '12p12cen': 106,\n",
       " '12x18': 107,\n",
       " '12yearold': 108,\n",
       " '13': 109,\n",
       " '130': 110,\n",
       " '1300': 111,\n",
       " '130000': 112,\n",
       " '1302': 113,\n",
       " '1305': 114,\n",
       " '1314': 115,\n",
       " '132': 116,\n",
       " '134': 117,\n",
       " '135': 118,\n",
       " '135000': 119,\n",
       " '136': 120,\n",
       " '137': 121,\n",
       " '1384': 122,\n",
       " '139nucleotide': 123,\n",
       " '13c': 124,\n",
       " '13dc': 125,\n",
       " '13th': 126,\n",
       " '14': 127,\n",
       " '1400': 128,\n",
       " '14008': 129,\n",
       " '142': 130,\n",
       " '1423': 131,\n",
       " '1429': 132,\n",
       " '145': 133,\n",
       " '146148': 134,\n",
       " '1470s': 135,\n",
       " '147earth': 136,\n",
       " '149': 137,\n",
       " '1496': 138,\n",
       " '14c': 139,\n",
       " '14dichlorobenzene': 140,\n",
       " '14inch': 141,\n",
       " '15': 142,\n",
       " '150': 143,\n",
       " '1500': 144,\n",
       " '15000': 145,\n",
       " '150000': 146,\n",
       " '1503': 147,\n",
       " '150w': 148,\n",
       " '151': 149,\n",
       " '1515': 150,\n",
       " '1520': 151,\n",
       " '1521': 152,\n",
       " '1536': 153,\n",
       " '154': 154,\n",
       " '1541': 155,\n",
       " '1561': 156,\n",
       " '15641642': 157,\n",
       " '156oc': 158,\n",
       " '1576': 159,\n",
       " '1578': 160,\n",
       " '1590': 161,\n",
       " '1593': 162,\n",
       " '15991600': 163,\n",
       " '15yearold': 164,\n",
       " '16': 165,\n",
       " '160': 166,\n",
       " '1600': 167,\n",
       " '16000': 168,\n",
       " '16001914': 169,\n",
       " '1600s': 170,\n",
       " '1609': 171,\n",
       " '161': 172,\n",
       " '1610': 173,\n",
       " '16235': 174,\n",
       " '165': 175,\n",
       " '1650': 176,\n",
       " '1659': 177,\n",
       " '166': 178,\n",
       " '1660': 179,\n",
       " '1661': 180,\n",
       " '1661027kg': 181,\n",
       " '168': 182,\n",
       " '1683': 183,\n",
       " '1687': 184,\n",
       " '1688': 185,\n",
       " '16tesla': 186,\n",
       " '17': 187,\n",
       " '170': 188,\n",
       " '172': 189,\n",
       " '1722a': 190,\n",
       " '173273': 191,\n",
       " '178': 192,\n",
       " '1786': 193,\n",
       " '1788': 194,\n",
       " '179': 195,\n",
       " '1799': 196,\n",
       " '17q23': 197,\n",
       " '17th': 198,\n",
       " '18': 199,\n",
       " '180': 200,\n",
       " '1800': 201,\n",
       " '18000': 202,\n",
       " '1800milethick': 203,\n",
       " '1800s': 204,\n",
       " '1801': 205,\n",
       " '1803': 206,\n",
       " '1811': 207,\n",
       " '18151865': 208,\n",
       " '182': 209,\n",
       " '183': 210,\n",
       " '1831': 211,\n",
       " '184': 212,\n",
       " '1850': 213,\n",
       " '1858': 214,\n",
       " '1859': 215,\n",
       " '1861': 216,\n",
       " '187': 217,\n",
       " '1875': 218,\n",
       " '18800': 219,\n",
       " '1888': 220,\n",
       " '1896': 221,\n",
       " '1898': 222,\n",
       " '189819': 223,\n",
       " '18c': 224,\n",
       " '18th': 225,\n",
       " '19': 226,\n",
       " '190': 227,\n",
       " '1900s': 228,\n",
       " '1901': 229,\n",
       " '1905': 230,\n",
       " '1909': 231,\n",
       " '1910': 232,\n",
       " '1916': 233,\n",
       " '1918': 234,\n",
       " '1923': 235,\n",
       " '1927': 236,\n",
       " '1928': 237,\n",
       " '1929': 238,\n",
       " '1930': 239,\n",
       " '1930s': 240,\n",
       " '1931': 241,\n",
       " '1932': 242,\n",
       " '193224': 243,\n",
       " '1936': 244,\n",
       " '1938': 245,\n",
       " '1940': 246,\n",
       " '1942': 247,\n",
       " '1944': 248,\n",
       " '1948': 249,\n",
       " '1950': 250,\n",
       " '1950s': 251,\n",
       " '1951': 252,\n",
       " '1953': 253,\n",
       " '1956': 254,\n",
       " '1957': 255,\n",
       " '1959': 256,\n",
       " '196': 257,\n",
       " '1960s': 258,\n",
       " '1962': 259,\n",
       " '1965': 260,\n",
       " '1966': 261,\n",
       " '1967': 262,\n",
       " '1968': 263,\n",
       " '19691974': 264,\n",
       " '197': 265,\n",
       " '1970s': 266,\n",
       " '1971': 267,\n",
       " '1972': 268,\n",
       " '1974': 269,\n",
       " '1976': 270,\n",
       " '1977': 271,\n",
       " '1978': 272,\n",
       " '1979': 273,\n",
       " '198': 274,\n",
       " '1980': 275,\n",
       " '198081': 276,\n",
       " '1980s': 277,\n",
       " '1981': 278,\n",
       " '1982': 279,\n",
       " '1983': 280,\n",
       " '1984': 281,\n",
       " '1985': 282,\n",
       " '1986': 283,\n",
       " '1988': 284,\n",
       " '1989': 285,\n",
       " '1990': 286,\n",
       " '1990s': 287,\n",
       " '1991': 288,\n",
       " '1991c': 289,\n",
       " '1992': 290,\n",
       " '1993': 291,\n",
       " '1994': 292,\n",
       " '1995': 293,\n",
       " '1996': 294,\n",
       " '1997': 295,\n",
       " '1998': 296,\n",
       " '1999': 297,\n",
       " '19q1213': 298,\n",
       " '19th': 299,\n",
       " '19valence': 300,\n",
       " '1a': 301,\n",
       " '1am': 302,\n",
       " '1b': 303,\n",
       " '1c10': 304,\n",
       " '1cell': 305,\n",
       " '1f': 306,\n",
       " '1infancy': 307,\n",
       " '1k': 308,\n",
       " '1mm': 309,\n",
       " '1naphthol': 310,\n",
       " '1s': 311,\n",
       " '1st': 312,\n",
       " '1the': 313,\n",
       " '2': 314,\n",
       " '20': 315,\n",
       " '200': 316,\n",
       " '2000': 317,\n",
       " '20000': 318,\n",
       " '200000': 319,\n",
       " '20000hz': 320,\n",
       " '2001': 321,\n",
       " '20010324': 322,\n",
       " '2002': 323,\n",
       " '2003': 324,\n",
       " '20032004': 325,\n",
       " '2004': 326,\n",
       " '2005': 327,\n",
       " '2006': 328,\n",
       " '2007': 329,\n",
       " '2008': 330,\n",
       " '2009': 331,\n",
       " '200m': 332,\n",
       " '2010': 333,\n",
       " '2010b': 334,\n",
       " '2011': 335,\n",
       " '2012': 336,\n",
       " '2013': 337,\n",
       " '2014': 338,\n",
       " '2016': 339,\n",
       " '2020000': 340,\n",
       " '2023': 341,\n",
       " '2025': 342,\n",
       " '20252050': 343,\n",
       " '2030': 344,\n",
       " '204': 345,\n",
       " '2050': 346,\n",
       " '206': 347,\n",
       " '207': 348,\n",
       " '208': 349,\n",
       " '2094': 350,\n",
       " '20deg': 351,\n",
       " '20hz': 352,\n",
       " '20letter': 353,\n",
       " '20q12q13': 354,\n",
       " '20th': 355,\n",
       " '21': 356,\n",
       " '211': 357,\n",
       " '2113': 358,\n",
       " '212': 359,\n",
       " '213': 360,\n",
       " '214': 361,\n",
       " '216': 362,\n",
       " '21714': 363,\n",
       " '218': 364,\n",
       " '21st': 365,\n",
       " '22': 366,\n",
       " '220': 367,\n",
       " '222': 368,\n",
       " '22223': 369,\n",
       " '222rn': 370,\n",
       " '2230': 371,\n",
       " '2247oc': 372,\n",
       " '225': 373,\n",
       " '226': 374,\n",
       " '2276': 375,\n",
       " '228': 376,\n",
       " '22km': 377,\n",
       " '23': 378,\n",
       " '230': 379,\n",
       " '230v': 380,\n",
       " '231': 381,\n",
       " '232425': 382,\n",
       " '23439': 383,\n",
       " '235': 384,\n",
       " '238': 385,\n",
       " '23c': 386,\n",
       " '23h': 387,\n",
       " '23rd': 388,\n",
       " '23x2': 389,\n",
       " '24': 390,\n",
       " '2400': 391,\n",
       " '241': 392,\n",
       " '244': 393,\n",
       " '2461': 394,\n",
       " '2477': 395,\n",
       " '2483254070512': 396,\n",
       " '2486': 397,\n",
       " '248800': 398,\n",
       " '24dichlorophenol': 399,\n",
       " '24h': 400,\n",
       " '24hour': 401,\n",
       " '24satellite': 402,\n",
       " '25': 403,\n",
       " '250': 404,\n",
       " '2500': 405,\n",
       " '25066': 406,\n",
       " '2514': 407,\n",
       " '253': 408,\n",
       " '2558200': 409,\n",
       " '256': 410,\n",
       " '257': 411,\n",
       " '25hour': 412,\n",
       " '25th': 413,\n",
       " '26': 414,\n",
       " '2600': 415,\n",
       " '26000': 416,\n",
       " '260000': 417,\n",
       " '2625': 418,\n",
       " '2627': 419,\n",
       " '268': 420,\n",
       " '27': 421,\n",
       " '270': 422,\n",
       " '27000': 423,\n",
       " '27000000': 424,\n",
       " '273': 425,\n",
       " '27315': 426,\n",
       " '27322': 427,\n",
       " '275': 428,\n",
       " '28': 429,\n",
       " '280': 430,\n",
       " '2800': 431,\n",
       " '28000': 432,\n",
       " '28250foot': 433,\n",
       " '28251': 434,\n",
       " '286': 435,\n",
       " '2865': 436,\n",
       " '287': 437,\n",
       " '2875': 438,\n",
       " '2894': 439,\n",
       " '28minute': 440,\n",
       " '29': 441,\n",
       " '2900': 442,\n",
       " '29028': 443,\n",
       " '29035': 444,\n",
       " '294': 445,\n",
       " '299792458th': 446,\n",
       " '2c': 447,\n",
       " '2call': 448,\n",
       " '2d': 449,\n",
       " '2element': 450,\n",
       " '2endogenous': 451,\n",
       " '2f': 452,\n",
       " '2fold': 453,\n",
       " '2n': 454,\n",
       " '2nd': 455,\n",
       " '2ndlaw': 456,\n",
       " '2p': 457,\n",
       " '2pm': 458,\n",
       " '2pn': 459,\n",
       " '2polyunsaturated': 460,\n",
       " '2quot': 461,\n",
       " '2s': 462,\n",
       " '3': 463,\n",
       " '30': 464,\n",
       " '300': 465,\n",
       " '3000': 466,\n",
       " '30000': 467,\n",
       " '3003000': 468,\n",
       " '301': 469,\n",
       " '3050': 470,\n",
       " '308': 471,\n",
       " '30c': 472,\n",
       " '30day': 473,\n",
       " '30foot': 474,\n",
       " '30ft': 475,\n",
       " '30minute': 476,\n",
       " '30n': 477,\n",
       " '31': 478,\n",
       " '310': 479,\n",
       " '311': 480,\n",
       " '314': 481,\n",
       " '316': 482,\n",
       " '317': 483,\n",
       " '3173': 484,\n",
       " '32': 485,\n",
       " '320': 486,\n",
       " '3200': 487,\n",
       " '320x240': 488,\n",
       " '3212': 489,\n",
       " '322': 490,\n",
       " '325000': 491,\n",
       " '329d': 492,\n",
       " '32f': 493,\n",
       " '33': 494,\n",
       " '330': 495,\n",
       " '33000': 496,\n",
       " '3328': 497,\n",
       " '333': 498,\n",
       " '334': 499,\n",
       " '336': 500,\n",
       " '337': 501,\n",
       " '34': 502,\n",
       " '3407': 503,\n",
       " '344': 504,\n",
       " '345280': 505,\n",
       " '35': 506,\n",
       " '350': 507,\n",
       " '3500': 508,\n",
       " '352': 509,\n",
       " '3545011': 510,\n",
       " '354b': 511,\n",
       " '3570': 512,\n",
       " '35kb': 513,\n",
       " '36': 514,\n",
       " '360': 515,\n",
       " '3600': 516,\n",
       " '3638': 517,\n",
       " '365': 518,\n",
       " '36525': 519,\n",
       " '36526': 520,\n",
       " '365day': 521,\n",
       " '36semesterhour': 522,\n",
       " '37': 523,\n",
       " '3700000': 524,\n",
       " '375': 525,\n",
       " '38': 526,\n",
       " '380': 527,\n",
       " '381': 528,\n",
       " '385': 529,\n",
       " '39': 530,\n",
       " '398': 531,\n",
       " '3amp4': 532,\n",
       " '3b': 533,\n",
       " '3c': 534,\n",
       " '3carbon': 535,\n",
       " '3d': 536,\n",
       " '3dimensional': 537,\n",
       " '3f4': 538,\n",
       " '3h2o': 539,\n",
       " '3hour': 540,\n",
       " '3methylcyclohexane': 541,\n",
       " '3p': 542,\n",
       " '3quot': 543,\n",
       " '3rd': 544,\n",
       " '3volt': 545,\n",
       " '3year': 546,\n",
       " '4': 547,\n",
       " '40': 548,\n",
       " '400': 549,\n",
       " '4000': 550,\n",
       " '40000': 551,\n",
       " '400km': 552,\n",
       " '40150': 553,\n",
       " '40307': 554,\n",
       " '40mph': 555,\n",
       " '40x': 556,\n",
       " '41': 557,\n",
       " '415': 558,\n",
       " '419': 559,\n",
       " '419kj': 560,\n",
       " '42': 561,\n",
       " '421': 562,\n",
       " '423b030': 563,\n",
       " '424': 564,\n",
       " '43': 565,\n",
       " '431': 566,\n",
       " '431d': 567,\n",
       " '433333333': 568,\n",
       " '435': 569,\n",
       " '44': 570,\n",
       " '44100': 571,\n",
       " '4413': 572,\n",
       " '443d': 573,\n",
       " '444': 574,\n",
       " '449': 575,\n",
       " '45': 576,\n",
       " '450': 577,\n",
       " '4530': 578,\n",
       " '454': 579,\n",
       " '45500': 580,\n",
       " '456': 581,\n",
       " '45700': 582,\n",
       " '459': 583,\n",
       " '45967': 584,\n",
       " '46': 585,\n",
       " '460': 586,\n",
       " '462b': 587,\n",
       " '46xy': 588,\n",
       " '47': 589,\n",
       " '474': 590,\n",
       " '477': 591,\n",
       " '48': 592,\n",
       " '480': 593,\n",
       " '4800': 594,\n",
       " '485': 595,\n",
       " '48week': 596,\n",
       " '49': 597,\n",
       " '490000': 598,\n",
       " '4a': 599,\n",
       " '4bps2': 600,\n",
       " '4chambered': 601,\n",
       " '4cls2': 602,\n",
       " '4d6there': 603,\n",
       " '4gram': 604,\n",
       " '4p': 605,\n",
       " '4phase': 606,\n",
       " '4th': 607,\n",
       " '4x3': 608,\n",
       " '5': 609,\n",
       " '50': 610,\n",
       " '500': 611,\n",
       " '5000': 612,\n",
       " '50000': 613,\n",
       " '505': 614,\n",
       " '507': 615,\n",
       " '50foot': 616,\n",
       " '51': 617,\n",
       " '513': 618,\n",
       " '514': 619,\n",
       " '518': 620,\n",
       " '52': 621,\n",
       " '520': 622,\n",
       " '53': 623,\n",
       " '5354': 624,\n",
       " '536': 625,\n",
       " '54': 626,\n",
       " '542': 627,\n",
       " '544': 628,\n",
       " '5442': 629,\n",
       " '546': 630,\n",
       " '55': 631,\n",
       " '550': 632,\n",
       " '55147': 633,\n",
       " '555': 634,\n",
       " '5587': 635,\n",
       " '559586': 636,\n",
       " '56': 637,\n",
       " '56000': 638,\n",
       " '560000': 639,\n",
       " '563': 640,\n",
       " '5635990': 641,\n",
       " '56m': 642,\n",
       " '57': 643,\n",
       " '570': 644,\n",
       " '5715': 645,\n",
       " '5730': 646,\n",
       " '5762': 647,\n",
       " '58': 648,\n",
       " '580000': 649,\n",
       " '585': 650,\n",
       " '586': 651,\n",
       " '588': 652,\n",
       " '59': 653,\n",
       " '590': 654,\n",
       " '599': 655,\n",
       " '5c': 656,\n",
       " '5carbon': 657,\n",
       " '5describe': 658,\n",
       " '5h103': 659,\n",
       " '5mm': 660,\n",
       " '5p': 661,\n",
       " '5th': 662,\n",
       " '5thmagnitude': 663,\n",
       " '5um': 664,\n",
       " '5x10': 665,\n",
       " '6': 666,\n",
       " '60': 667,\n",
       " '600': 668,\n",
       " '6000': 669,\n",
       " '6000000': 670,\n",
       " '600630': 671,\n",
       " '603': 672,\n",
       " '604': 673,\n",
       " '6070': 674,\n",
       " '61': 675,\n",
       " '615000': 676,\n",
       " '616': 677,\n",
       " '62': 678,\n",
       " '6200': 679,\n",
       " '6265': 680,\n",
       " '63': 681,\n",
       " '630pm': 682,\n",
       " '631': 683,\n",
       " '6360': 684,\n",
       " '639': 685,\n",
       " '64': 686,\n",
       " '640x480': 687,\n",
       " '64bit': 688,\n",
       " '65': 689,\n",
       " '650c': 690,\n",
       " '6533': 691,\n",
       " '656': 692,\n",
       " '6570': 693,\n",
       " '66': 694,\n",
       " '6660': 695,\n",
       " '67': 696,\n",
       " '678': 697,\n",
       " '68': 698,\n",
       " '69': 699,\n",
       " '696': 700,\n",
       " '6r4': 701,\n",
       " '6th': 702,\n",
       " '6week': 703,\n",
       " '7': 704,\n",
       " '70': 705,\n",
       " '700': 706,\n",
       " '7000': 707,\n",
       " '70000': 708,\n",
       " '707': 709,\n",
       " '71': 710,\n",
       " '710': 711,\n",
       " '711': 712,\n",
       " '718111': 713,\n",
       " '72': 714,\n",
       " '722021': 715,\n",
       " '7243': 716,\n",
       " '73': 717,\n",
       " '73degree': 718,\n",
       " '74': 719,\n",
       " '740': 720,\n",
       " '7400': 721,\n",
       " '7411': 722,\n",
       " '7415': 723,\n",
       " '7457': 724,\n",
       " '746': 725,\n",
       " '75': 726,\n",
       " '750': 727,\n",
       " '7500': 728,\n",
       " '750000': 729,\n",
       " '760': 730,\n",
       " '767': 731,\n",
       " '775': 732,\n",
       " '779': 733,\n",
       " '78': 734,\n",
       " '780000': 735,\n",
       " '7808': 736,\n",
       " '79': 737,\n",
       " '7f': 738,\n",
       " '7h': 739,\n",
       " '7mm': 740,\n",
       " '7segmented': 741,\n",
       " '8': 742,\n",
       " '80': 743,\n",
       " '800': 744,\n",
       " '8000': 745,\n",
       " '80000': 746,\n",
       " '8047': 747,\n",
       " '8085': 748,\n",
       " '81': 749,\n",
       " '8125': 750,\n",
       " '818': 751,\n",
       " '82': 752,\n",
       " '83': 753,\n",
       " '84': 754,\n",
       " '840': 755,\n",
       " '84013': 756,\n",
       " '840a': 757,\n",
       " '85': 758,\n",
       " '8611': 759,\n",
       " '8611m': 760,\n",
       " '8612': 761,\n",
       " '86400': 762,\n",
       " '867': 763,\n",
       " '8680': 764,\n",
       " '8751': 765,\n",
       " '88': 766,\n",
       " '8800': 767,\n",
       " '89': 768,\n",
       " '891': 769,\n",
       " '895': 770,\n",
       " '8a': 771,\n",
       " '8d': 772,\n",
       " '8h': 773,\n",
       " '8hour': 774,\n",
       " '8i1': 775,\n",
       " '8i2': 776,\n",
       " '8oxodg': 777,\n",
       " '8oxodgtp': 778,\n",
       " '8q22ter': 779,\n",
       " '8week': 780,\n",
       " '9': 781,\n",
       " '90': 782,\n",
       " '9002': 783,\n",
       " '9095': 784,\n",
       " '90mm': 785,\n",
       " '90sr': 786,\n",
       " '91': 787,\n",
       " '912': 788,\n",
       " '9192': 789,\n",
       " '92': 790,\n",
       " '925': 791,\n",
       " '928': 792,\n",
       " '92k': 793,\n",
       " '93': 794,\n",
       " '932': 795,\n",
       " '94': 796,\n",
       " '9446': 797,\n",
       " '95': 798,\n",
       " '956978': 799,\n",
       " '96': 800,\n",
       " '962': 801,\n",
       " '965': 802,\n",
       " '97': 803,\n",
       " '972': 804,\n",
       " '98': 805,\n",
       " '981': 806,\n",
       " '99': 807,\n",
       " '994': 808,\n",
       " '996': 809,\n",
       " '9985': 810,\n",
       " '9986': 811,\n",
       " '9be': 812,\n",
       " '9evolutionary': 813,\n",
       " '9students': 814,\n",
       " '___': 815,\n",
       " '____': 816,\n",
       " '_____': 817,\n",
       " '________': 818,\n",
       " '____________________________': 819,\n",
       " '___________________________________________': 820,\n",
       " '______________________________________________________________________': 821,\n",
       " 'a1': 822,\n",
       " 'a2': 823,\n",
       " 'a4': 824,\n",
       " 'a85125098': 825,\n",
       " 'a97': 826,\n",
       " 'aampp': 827,\n",
       " 'ab': 828,\n",
       " 'abandon': 829,\n",
       " 'abandoned': 830,\n",
       " 'abbreviated': 831,\n",
       " 'abbreviation': 832,\n",
       " 'abc': 833,\n",
       " 'abcc6': 834,\n",
       " 'abcd': 835,\n",
       " 'abdomen': 836,\n",
       " 'abdominal': 837,\n",
       " 'abdominals': 838,\n",
       " 'abductor': 839,\n",
       " 'aberration': 840,\n",
       " 'aberrations': 841,\n",
       " 'abide': 842,\n",
       " 'abilities': 843,\n",
       " 'ability': 844,\n",
       " 'abiotic': 845,\n",
       " 'abioticproducerconsumerdecomposer': 846,\n",
       " 'ablation': 847,\n",
       " 'able': 848,\n",
       " 'ablution': 849,\n",
       " 'abnormal': 850,\n",
       " 'abnormalities': 851,\n",
       " 'abnormally': 852,\n",
       " 'abo': 853,\n",
       " 'abortion': 854,\n",
       " 'abortions': 855,\n",
       " 'abovedescribed': 856,\n",
       " 'aboveground': 857,\n",
       " 'abq': 858,\n",
       " 'abrasion': 859,\n",
       " 'abrasive': 860,\n",
       " 'abrasives': 861,\n",
       " 'abruption': 862,\n",
       " 'abruptly': 863,\n",
       " 'abscess': 864,\n",
       " 'abscesses': 865,\n",
       " 'absence': 866,\n",
       " 'absent': 867,\n",
       " 'absolute': 868,\n",
       " 'absolutely': 869,\n",
       " 'absolutevalue': 870,\n",
       " 'absorb': 871,\n",
       " 'absorbable': 872,\n",
       " 'absorbed': 873,\n",
       " 'absorbent': 874,\n",
       " 'absorber': 875,\n",
       " 'absorbing': 876,\n",
       " 'absorbs': 877,\n",
       " 'absorption': 878,\n",
       " 'absorptive': 879,\n",
       " 'abstarct': 880,\n",
       " 'abstract': 881,\n",
       " 'abundance': 882,\n",
       " 'abundances': 883,\n",
       " 'abundant': 884,\n",
       " 'abundantly': 885,\n",
       " 'abuse': 886,\n",
       " 'ac': 887,\n",
       " 'acacia': 888,\n",
       " 'academic': 889,\n",
       " 'academical': 890,\n",
       " 'academy': 891,\n",
       " 'accc': 892,\n",
       " 'accelerate': 893,\n",
       " 'accelerated': 894,\n",
       " 'accelerates': 895,\n",
       " 'accelerating': 896,\n",
       " 'acceleration': 897,\n",
       " 'accelerations': 898,\n",
       " 'accelerometers': 899,\n",
       " 'accent': 900,\n",
       " 'accentuation': 901,\n",
       " 'accept': 902,\n",
       " 'acceptable': 903,\n",
       " 'acceptance': 904,\n",
       " 'accepted': 905,\n",
       " 'accepting': 906,\n",
       " 'acceptor': 907,\n",
       " 'acceptors': 908,\n",
       " 'accepts': 909,\n",
       " 'access': 910,\n",
       " 'accessed': 911,\n",
       " 'accessible': 912,\n",
       " 'accessories': 913,\n",
       " 'accessory': 914,\n",
       " 'accident': 915,\n",
       " 'accidental': 916,\n",
       " 'accidents': 917,\n",
       " 'accidentsinjury': 918,\n",
       " 'acclaimed': 919,\n",
       " 'acclimatization': 920,\n",
       " 'acclimatize': 921,\n",
       " 'accommodate': 922,\n",
       " 'accommodates': 923,\n",
       " 'accommodations': 924,\n",
       " 'accompanied': 925,\n",
       " 'accompanies': 926,\n",
       " 'accompany': 927,\n",
       " 'accompanying': 928,\n",
       " 'accomplish': 929,\n",
       " 'accomplished': 930,\n",
       " 'accomplishes': 931,\n",
       " 'accomplishment': 932,\n",
       " 'accomplishments': 933,\n",
       " 'accord': 934,\n",
       " 'accordance': 935,\n",
       " 'according': 936,\n",
       " 'accordingly': 937,\n",
       " 'account': 938,\n",
       " 'accounted': 939,\n",
       " 'accounting': 940,\n",
       " 'accounts': 941,\n",
       " 'accreta': 942,\n",
       " 'accretion': 943,\n",
       " 'accumulate': 944,\n",
       " 'accumulated': 945,\n",
       " 'accumulates': 946,\n",
       " 'accumulation': 947,\n",
       " 'accuracy': 948,\n",
       " 'accurate': 949,\n",
       " 'accurately': 950,\n",
       " 'accustomed': 951,\n",
       " 'acdk': 952,\n",
       " 'acetal': 953,\n",
       " 'acetaldehyde': 954,\n",
       " 'acetate': 955,\n",
       " 'acetates': 956,\n",
       " 'acetic': 957,\n",
       " 'acetone': 958,\n",
       " 'acetonitrile': 959,\n",
       " 'acetyl': 960,\n",
       " 'acetylation': 961,\n",
       " 'acetylcholine': 962,\n",
       " 'acetylene': 963,\n",
       " 'ach': 964,\n",
       " 'achaeal': 965,\n",
       " 'achievable': 966,\n",
       " 'achieve': 967,\n",
       " 'achieved': 968,\n",
       " 'achievements': 969,\n",
       " 'achieving': 970,\n",
       " 'achilles': 971,\n",
       " 'achromatic': 972,\n",
       " 'acid': 973,\n",
       " 'acidbase': 974,\n",
       " 'acidforming': 975,\n",
       " 'acidic': 976,\n",
       " 'acidification': 977,\n",
       " 'acidity': 978,\n",
       " 'acidophile': 979,\n",
       " 'acidophiles': 980,\n",
       " 'acidophilic': 981,\n",
       " 'acidosis': 982,\n",
       " 'acidpepsin': 983,\n",
       " 'acids': 984,\n",
       " 'acidtrna': 985,\n",
       " 'acidulous': 986,\n",
       " 'acinetobacter': 987,\n",
       " 'acknowledged': 988,\n",
       " 'acks': 989,\n",
       " 'acme': 990,\n",
       " 'acorn': 991,\n",
       " 'acornoaktree': 992,\n",
       " 'acorns': 993,\n",
       " 'acoustic': 994,\n",
       " 'acoustics': 995,\n",
       " 'acquainted': 996,\n",
       " 'acquifers': 997,\n",
       " 'acquire': 998,\n",
       " 'acquired': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2358751",
   "metadata": {},
   "source": [
    "# Build Embedding Model using Gensim and FastText\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9c274b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1a241c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 1024\n",
    "learn_rate = 0.01\n",
    "embedding_size = 200\n",
    "no_of_epochs = 8\n",
    "window_size = 8\n",
    "vocab_size = len(unique_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d4dea990",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_t_dataset = clean_train_dataset['premise'] + clean_train_dataset['hypothesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f5cb6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model = FastText(clean_t_dataset, \n",
    "                           vector_size=embedding_size,\n",
    "                           window=window_size,\n",
    "                           sg=1,\n",
    "                           epochs=no_of_epochs\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f01dcf2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saturns', 0.9604904055595398),\n",
       " ('1980', 0.8468125462532043),\n",
       " ('voyager', 0.8449878096580505),\n",
       " ('1979', 0.8226709365844727),\n",
       " ('neptune', 0.8205943703651428),\n",
       " ('spacecraft', 0.819324254989624),\n",
       " ('jupiter', 0.7984594106674194),\n",
       " ('1989', 0.7962067723274231),\n",
       " ('1981', 0.7874003052711487),\n",
       " ('1980s', 0.7858580946922302)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_model.wv.most_similar('saturn', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44a81f2",
   "metadata": {},
   "source": [
    "# Transformer Model Implementation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
