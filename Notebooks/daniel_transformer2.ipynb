{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2966fb6e",
   "metadata": {},
   "source": [
    "# Transformer code with components split for better understanding and easier manipulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2e22dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os \n",
    "\n",
    "sys.path.append(os.path.abspath('..')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb2ae53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DCCN9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DCCN9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\DCCN9\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import Pre-Processing\n",
    "from src.pre_processing import clean_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91042ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.9\n",
      "Number of GPUs: 1\n",
      "GPU name: NVIDIA GeForce MX450\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54c8bd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('../Dataset/train.json')\n",
    "test_df = pd.read_json('../Dataset/test.json')\n",
    "validation_df = pd.read_json('../Dataset/validation.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1c22c",
   "metadata": {},
   "source": [
    "# Pre Processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760b2933",
   "metadata": {},
   "source": [
    "Call the pre-processing fucntion inside the src --> pre-processing.clean_dataset()  \n",
    "Structure :\n",
    "`clean_dataset(dataset, MIN_WORD_LENGTH=3, MAX_WORD_LENGTH=50, method=None, pos_filter=False, stop_w=False)`\n",
    "\n",
    "- dataset\n",
    "- min_word_len --> Set to 3\n",
    "- max_word_len --> Set to 60\n",
    "- method (stem,lemmatize) optional\n",
    "- pos_filter (optional)\n",
    "- stop_word (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06454ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_dataset = clean_dataset(train_df, stop_w=False, method='', pos_filter=False)\n",
    "clean_test_dataset = clean_dataset(test_df,stop_w=False, method=None, pos_filter= False )\n",
    "clean_validation_dataset = clean_dataset(validation_df,stop_w=False, method=None, pos_filter= False )\n",
    "\n",
    "# Combine between clean premise and hypothesis\n",
    "clean_t_dataset = clean_train_dataset['premise'] + clean_train_dataset['hypothesis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d402eaca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [pluto, rotates, once, on, its, axis, every, 6...\n",
       "1    [glenn, once, per, day, the, earth, rotates, a...\n",
       "2    [geysers, periodic, gush, of, hot, water, at, ...\n",
       "3    [facts, liquid, water, droplets, can, be, chan...\n",
       "4    [by, comparison, the, earth, rotates, on, its,...\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_t_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd40e91b",
   "metadata": {},
   "source": [
    "## Create a unique list of words from both premise and hypothesis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04ce4a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of unique words: 22134\n"
     ]
    }
   ],
   "source": [
    "# Create a unique word list from the cleaned dataset\n",
    "unique_words = set()\n",
    "for sentence in clean_t_dataset: # Both Premise and Hypothesis \n",
    "    for word in sentence:\n",
    "        unique_words.add(word)\n",
    "\n",
    "print(f\"Count of unique words: {len(unique_words)}\")\n",
    "# No lemma, stem, stop_w, pos_filter = 22134\n",
    "# With stop_w = 21917\n",
    "# With stop_w, lemma (took 25 sec) = 18396\n",
    "# With stop_w, stem (took 10s) = 15403\n",
    "# Just Stem = 15565\n",
    "# Just lemma = 18587\n",
    "# Just Pos Filtering = 21115\n",
    "# What are we removing in the pos filtering???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de69e90",
   "metadata": {},
   "source": [
    "Sort the word to always have tem ordered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d6c86d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_list = sorted(list(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d140757",
   "metadata": {},
   "source": [
    "## Create a dictionary of word-index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d5b4fb",
   "metadata": {},
   "source": [
    "Use the enumerate to map a unique index to a unique word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3fcf8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {w:i for i,w in enumerate(unique_words_list)}\n",
    "id2word = {i:w for i,w in enumerate(unique_words_list)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab02d5d",
   "metadata": {},
   "source": [
    "# Build the Embedding Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a8f88",
   "metadata": {},
   "source": [
    "Build the embeddings using the gensim, calling the `embedding_model.py`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eda725ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8ad50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Hyperparameters\n",
    "emdedding_batch_size = 1024\n",
    "embedding_learn_rate = 0.001\n",
    "embedding_size = 200\n",
    "embedding_no_of_epochs = 8\n",
    "embedding_window_size = 3\n",
    "vocab_size = len(unique_words)\n",
    "# sg -->  0 CBOW, 1 skip-gram \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb593df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text_model = FastText(clean_t_dataset, # Both premise and Hypothesis \n",
    "                           vector_size=embedding_size,\n",
    "                           window=embedding_window_size,\n",
    "                           sg=1,\n",
    "                           epochs=embedding_no_of_epochs\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa798437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('saturns', 0.9502517580986023),\n",
       " ('neptune', 0.8259016871452332),\n",
       " ('1980', 0.8240558505058289),\n",
       " ('1979', 0.7945947647094727),\n",
       " ('1981', 0.7814427018165588),\n",
       " ('voyager', 0.7696138024330139),\n",
       " ('1980s', 0.7681811451911926),\n",
       " ('180', 0.7674251198768616),\n",
       " ('1989', 0.7645599246025085),\n",
       " ('80', 0.7556518912315369)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_text_model.wv.most_similar('saturn', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9a8a72",
   "metadata": {},
   "source": [
    "# Start of the Transformer Implementation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712f54be",
   "metadata": {},
   "source": [
    "## Lets first add the necessary special tokens [SEP] [PAD]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3106a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKENS = ['[PAD]','[UNK]','[CLS]','[SEP]']\n",
    "for tok in SPECIAL_TOKENS:\n",
    "    if tok not in word2id:\n",
    "        idx = len(word2id)\n",
    "        word2id[tok] = idx\n",
    "        id2word[idx] = tok\n",
    "\n",
    "PAD_ID = word2id['[PAD]'] # Padding token \n",
    "UNK_ID = word2id['[UNK]'] # Unknown words token \n",
    "CLS_ID = word2id['[CLS]'] # Classification token\n",
    "SEP_ID = word2id['[SEP]'] # Separation token "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc8173c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Hyper params\n",
    "MAX_SEQ_LEN = 64\n",
    "#embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "281b5a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_transformer_data(df, word2id, max_len):\n",
    "    input_ids = []\n",
    "    attention_mask = []\n",
    "    labels = []\n",
    "\n",
    "    label_map = {'neutral': 0, 'entails': 1}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        premise_toks = row['premise']\n",
    "        hypothesis_toks = row['hypothesis']\n",
    "        label = row['label']\n",
    "\n",
    "        # Add special tokens \n",
    "        tokens = [CLS_ID] \\\n",
    "                + [word2id.get(w,UNK_ID) for w in premise_toks] \\\n",
    "                + [SEP_ID] \\\n",
    "                + [word2id.get(w,UNK_ID) for w in hypothesis_toks] \n",
    "        # Truncate\n",
    "        tokens = tokens[:max_len]\n",
    "\n",
    "        # Attention mask \n",
    "        attn = [1] * len(tokens)\n",
    "\n",
    "        # Pad\n",
    "        pad_len = max_len- len(tokens) # To fill the [PAD]\n",
    "        if pad_len > 0:\n",
    "            tokens += [PAD_ID] * pad_len\n",
    "            attn += [0] * pad_len # FLag positions as padding \n",
    "\n",
    "        input_ids.append(tokens)\n",
    "        attention_mask.append(attn)\n",
    "        labels.append(label_map[label])\n",
    "\n",
    "    return (torch.LongTensor(input_ids),\n",
    "            torch.LongTensor(attention_mask),\n",
    "            torch.LongTensor(labels))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5068195b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: torch.Size([22905, 64])\n",
      "Shape of train_masks: torch.Size([22905, 64])\n",
      "Shape of y_train: torch.Size([22905])\n",
      "\n",
      "--- Example ---\n",
      "First example real length (mask sum): 22\n",
      "First example PAD count: 42\n"
     ]
    }
   ],
   "source": [
    "# Build train/test\n",
    "x_train, train_masks, y_train = prepare_transformer_data(clean_train_dataset, word2id, MAX_SEQ_LEN)\n",
    "x_test,  test_masks,  y_test  = prepare_transformer_data(clean_test_dataset,  word2id, MAX_SEQ_LEN)\n",
    "x_valid,  valid_masks,  y_valid  = prepare_transformer_data(clean_validation_dataset,  word2id, MAX_SEQ_LEN)\n",
    "\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of train_masks:\", train_masks.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "\n",
    "# Sanity Check \n",
    "i = 0\n",
    "print(\"\\n--- Example ---\")\n",
    "print(\"First example real length (mask sum):\", int(train_masks[i].sum()))\n",
    "print(\"First example PAD count:\", int((train_masks[i]==0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a8daab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34f9726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence = []\n",
    "# for x in x_train[0]:\n",
    "#     sentence.append(id2word[int(x)])\n",
    "\n",
    "# sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25988d3e",
   "metadata": {},
   "source": [
    "## Positional Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c03f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,max_len = 512, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0,max_len).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:,0::2] = torch.sin(position * div_term) # For even dims\n",
    "        pe[:,1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.pe[:, :x.size(1), :] \n",
    "        return self.dropout(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c54391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_embedding_matrix(word2id, pretrained_vectors, embedding_size):\n",
    "    vocab_size = len(word2id)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_size), dtype=np.float32)\n",
    "\n",
    "    # Fill the matrix with pre-trained vectors\n",
    "    for word, idx in word2id.items():\n",
    "        if word == '[PAD]':\n",
    "            continue\n",
    "        try:\n",
    "            vec = pretrained_vectors[word]\n",
    "            if vec.shape[0] == embedding_size:\n",
    "                embedding_matrix[idx] = vec.astype(np.float32)\n",
    "            else:\n",
    "                # fallback if dims don’t match\n",
    "                embedding_matrix[idx] = np.random.normal(0.0, 0.02, size=(embedding_size,)).astype(np.float32)\n",
    "        except KeyError:\n",
    "            # special tokens or OOV start them with random values \n",
    "            embedding_matrix[idx] = np.random.normal(0.0, 0.02, size=(embedding_size,)).astype(np.float32)\n",
    "\n",
    "    print(\"Embedding matrix created with shape:\", embedding_matrix.shape)\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b372ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix created with shape: (22138, 200)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = build_embedding_matrix(word2id, fast_text_model.wv, embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e64d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer Hyperparameters\n",
    "EMBEDDING_DIM = embedding_size\n",
    "N_HEADS = 3\n",
    "N_LAYERS = 1\n",
    "DROPOUT = 0.3\n",
    "NUM_CLASSES = 2\n",
    "BATCH_SIZE = 64\n",
    "LR = 0.0002\n",
    "WD = 0.2\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35ec7f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, embedding_matrix, num_classes, n_heads, n_layers, dropout):\n",
    "        super().__init__()\n",
    "        vocab_size, embed_dim = embedding_matrix.shape\n",
    "        self.d_model = embed_dim\n",
    "\n",
    "        # Embedding Layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False, padding_idx=PAD_ID)\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=MAX_SEQ_LEN, dropout=dropout)\n",
    "\n",
    "        # Transformer Encoder Layers\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=n_heads,\n",
    "            dropout=dropout,\n",
    "            dim_feedforward=256,\n",
    "            batch_first=True # Makes working with batch dimension easier\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=n_layers)\n",
    "\n",
    "        # Final Classification Head\n",
    "        self.classifier = nn.Linear(embed_dim,num_classes)\n",
    "\n",
    "    def forward(self, src, src_mask):\n",
    "        padding_mask = (src_mask == 0)\n",
    "\n",
    "        # Apply embedding and positional encoding\n",
    "        embedded = self.embedding(src) * math.sqrt(self.d_model)\n",
    "        pos_encoded = self.pos_encoder(embedded)\n",
    "\n",
    "        # Pass trough the transformer encoder\n",
    "        encoded = self.transformer_encoder(pos_encoded,src_key_padding_mask = padding_mask)\n",
    "\n",
    "        # Use the output of the [CLS] token (first token) for classification\n",
    "        cls_output = encoded[:,0,:]\n",
    "\n",
    "        # Get final logits from the classifier\n",
    "        logits = self.classifier(cls_output)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0760f460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix created with shape: (22138, 200)\n"
     ]
    }
   ],
   "source": [
    "# First, build the embedding matrix using the function you wrote\n",
    "embedding_matrix = build_embedding_matrix(word2id, fast_text_model.wv, EMBEDDING_DIM)\n",
    "\n",
    "# Now, instantiate the model\n",
    "transformer_model = TransformerClassifier(\n",
    "    embedding_matrix=embedding_matrix,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    n_heads=N_HEADS,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout=DROPOUT\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be2566a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ffdaf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_ds = TensorDataset(x_train, train_masks,y_train)\n",
    "test_ds = TensorDataset(x_test, test_masks,y_test)\n",
    "valid_ds = TensorDataset(x_valid, valid_masks,y_valid)\n",
    "\n",
    "# Dataloaders (shuffle for train)\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79908281",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model.to(device)\n",
    "\n",
    "class_weights = torch.tensor([1.0, 1.5]).to(device) \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr = LR, weight_decay=WD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "989a6600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for xb, mb, yb in loader: # x_train, train_mask, y_train\n",
    "        xb,mb,yb = xb.to(device), mb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(xb, mb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * yb.size(0)\n",
    "        preds = logits.argmax(1)\n",
    "        total_correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    return total_loss/total, total_correct/total\n",
    "\n",
    "@torch.no_grad() #For everything inside this function, don’t track gradients.\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total = 0\n",
    "    for input_ids, attention_mask, labels in loader:\n",
    "        input_ids      = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels         = labels.to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss   = criterion(logits, labels)\n",
    "\n",
    "        total_loss   += loss.item() * labels.size(0)\n",
    "        preds         = logits.argmax(1)\n",
    "        total_correct+= (preds == labels).sum().item()\n",
    "        total        += labels.size(0)\n",
    "    return total_loss/total, total_correct/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89462eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DCCN9\\OneDrive - UWA\\Data Science\\Semester July-November 2025\\CITS4012 - Natural Language Processing\\Team Assignment 2 NLP\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Train Loss: 0.6915, Train Acc: 0.5838 - Val Loss: 0.6514, Val Acc: 0.6628\n",
      "Epoch 2/3 - Train Loss: 0.6333, Train Acc: 0.6565 - Val Loss: 0.6546, Val Acc: 0.6674\n",
      "Epoch 3/3 - Train Loss: 0.5975, Train Acc: 0.6865 - Val Loss: 0.8009, Val Acc: 0.6406\n",
      "Training complete.\n",
      "FINAL TEST - Loss: 0.7495, Acc: 0.6899\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "transformer_model.to(device)\n",
    "print(device)\n",
    "# Main training loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss, train_acc = train_epoch(transformer_model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(transformer_model, valid_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} - Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "test_loss, test_acc = evaluate(transformer_model, test_loader, criterion, device)\n",
    "print(f\"FINAL TEST - Loss: {test_loss:.4f}, Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cef84ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6898674242424242\n",
      "F1 Score: 0.4527986633249791\n",
      "Precision: 0.7633802816901408\n",
      "Recall: 0.32185273159144895\n",
      "----------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     neutral       0.68      0.93      0.78      1270\n",
      "     entails       0.76      0.32      0.45       842\n",
      "\n",
      "    accuracy                           0.69      2112\n",
      "   macro avg       0.72      0.63      0.62      2112\n",
      "weighted avg       0.71      0.69      0.65      2112\n",
      "\n",
      "----------------------------------------\n",
      "Hyperparameters\n",
      "Batch Size 128\n",
      "Num of Epochs 3\n",
      "Learning Rate 0.0002\n",
      "Num Classes 2\n",
      "Number of Heads 4\n",
      "Numer of Layers 2\n",
      "Embedding Dimensions 200\n",
      "Dropout 0.4\n",
      "Weight Decay 0.2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report\n",
    "\n",
    "transformer_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for input_ids, attention_mask, labels in test_loader:\n",
    "        input_ids      = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels         = labels.to(device)\n",
    "\n",
    "        logits = transformer_model(input_ids, attention_mask)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "print(\"F1 Score:\", f1_score(all_labels, all_preds))\n",
    "print(\"Precision:\", precision_score(all_labels, all_preds))\n",
    "print(\"Recall:\", recall_score(all_labels, all_preds))\n",
    "print(\"-\" * 40)\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"neutral\",\"entails\"]))\n",
    "\n",
    "print('-' * 40)\n",
    "print('Hyperparameters')\n",
    "print('Batch Size', BATCH_SIZE)\n",
    "print('Num of Epochs', NUM_EPOCHS)\n",
    "print('Learning Rate', LR)\n",
    "print('Num Classes', NUM_CLASSES)\n",
    "print('Number of Heads', N_HEADS)\n",
    "print('Numer of Layers', N_LAYERS)\n",
    "print('Embedding Dimensions', EMBEDDING_DIM)\n",
    "print('Dropout', DROPOUT)\n",
    "print('Weight Decay', WD)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
