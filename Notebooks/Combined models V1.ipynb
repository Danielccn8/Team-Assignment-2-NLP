{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 CITS4012 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "Number of GPUs: 1\n",
            "GPU name: NVIDIA GeForce RTX 3060\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Josh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Josh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Josh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sys\n",
        "import os \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import copy\n",
        "import random\n",
        "\n",
        "import nltk\n",
        "if not nltk.download('punkt'):\n",
        "    nltk.download('punkt')\n",
        "    nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "if not nltk.download('stopwords'):\n",
        "    nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Stemmer and Lemmatizer\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag, word_tokenize\n",
        "\n",
        "if not nltk.download('wordnet'):\n",
        "    nltk.download('wordnet')\n",
        "    nltk.download('omw-1.4')\n",
        "    nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "sys.path.append(os.path.abspath('..')) \n",
        "import math\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch, torch.nn as nn, torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"CUDA version:\", torch.version.cuda)\n",
        "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "# Helper functions for training\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.Dataset Processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Config\n",
        "MIN_WORD_LENGTH = 3\n",
        "MAX_WORD_LENGTH = 60 \n",
        "\n",
        "# These are common English contractions.\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n",
        "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
        "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\",\n",
        "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
        "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
        "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
        "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\",\n",
        "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n",
        "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
        "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
        "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "\n",
        "# Helper function for lemmatization with POS tagging\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Default to noun if no match\n",
        "    \n",
        "# Allowed POS tags for filtering (example: nouns, verbs, adjectives, adverbs)\n",
        "allowed_pos_tags = {'NN', 'NNS', 'NNP', 'NNPS',   # Nouns\n",
        "                    'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ',  # Verbs\n",
        "                    'JJ', 'JJR', 'JJS',           # Adjectives\n",
        "                    'RB', 'RBR', 'RBS'}           # Adverbs\n",
        "\n",
        "# Filter the desired POS tags\n",
        "def filter_tokens_by_pos(tokens):\n",
        "    tagged_tokens = pos_tag(tokens)\n",
        "    filtered = [word for word, tag in tagged_tokens if tag in allowed_pos_tags]\n",
        "    return filtered\n",
        "\n",
        "def clean_dataset(dataset, MIN_WORD_LENGTH=3, MAX_WORD_LENGTH=60, method=['stem, lemmatize'], pos_filter=False, stop_w=False):\n",
        "    cleaned_premises = []\n",
        "    cleaned_hypotheses = []\n",
        "    cleaned_labels = []\n",
        "\n",
        "    for index, row in dataset.iterrows():\n",
        "        premise = row['premise']\n",
        "        hypothesis = row['hypothesis']\n",
        "        label = row['label']\n",
        "\n",
        "        # Lowercase\n",
        "        premise = premise.lower()\n",
        "        hypothesis = hypothesis.lower()\n",
        "\n",
        "        # Expand contractions\n",
        "        for contraction, full_form in contraction_dict.items():\n",
        "            premise = premise.replace(contraction, full_form)\n",
        "            hypothesis = hypothesis.replace(contraction, full_form)\n",
        "\n",
        "        # Remove punctuation/special chars\n",
        "        premise = re.sub(r'[^\\w\\s]', '', premise)\n",
        "        hypothesis = re.sub(r'[^\\w\\s]', '', hypothesis)\n",
        "\n",
        "        # Replace underscores/hyphens with spaces, then normalize whitespace\n",
        "        premise = re.sub(r'[-–—_]+', ' ', premise)\n",
        "        hypothesis = re.sub(r'[-–—_]+', ' ', hypothesis)\n",
        "\n",
        "        # Normalize whitespace\n",
        "        premise = re.sub(r'\\s+', ' ', premise).strip()\n",
        "        hypothesis = re.sub(r'\\s+', ' ', hypothesis).strip()\n",
        "\n",
        "\n",
        "        # Normalize whitespace\n",
        "        premise = re.sub(r'\\s+', ' ', premise).strip()\n",
        "        hypothesis = re.sub(r'\\s+', ' ', hypothesis).strip()\n",
        "\n",
        "        # Tokenization\n",
        "        premise_tokens = word_tokenize(premise)\n",
        "        hypothesis_tokens = word_tokenize(hypothesis)\n",
        "\n",
        "        # Replace numbers with '<NUM>'\n",
        "        premise_tokens = ['[NUM]' if any(char.isdigit() for char in word) else word for word in premise_tokens]\n",
        "        hypothesis_tokens = ['[NUM]' if any(char.isdigit() for char in word) else word for word in hypothesis_tokens]\n",
        "\n",
        "\n",
        "        # Stemming/Lemmatization\n",
        "        if 'stem' in method:\n",
        "            stemmer = PorterStemmer()\n",
        "            premise_tokens = [stemmer.stem(word) for word in premise_tokens]\n",
        "            hypothesis_tokens = [stemmer.stem(word) for word in hypothesis_tokens]\n",
        "        elif 'lemmatize' in method:\n",
        "            lemmatizer = WordNetLemmatizer()\n",
        "            premise_pos_tags = pos_tag(premise_tokens)\n",
        "            hypothesis_pos_tags = pos_tag(hypothesis_tokens)\n",
        "            premise_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in premise_pos_tags]\n",
        "            hypothesis_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(pos)) for word, pos in hypothesis_pos_tags]\n",
        "\n",
        "        # POS Filtering\n",
        "        if pos_filter:\n",
        "            premise_tokens = filter_tokens_by_pos(premise_tokens)\n",
        "            hypothesis_tokens = filter_tokens_by_pos(hypothesis_tokens)\n",
        "\n",
        "        # Remove stop words\n",
        "        if stop_w:\n",
        "            premise_tokens = [word for word in premise_tokens if word not in stop_words]\n",
        "            hypothesis_tokens = [word for word in hypothesis_tokens if word not in stop_words]\n",
        "\n",
        "        # Now check token length AFTER cleaning\n",
        "        if (MIN_WORD_LENGTH <= len(premise_tokens) <= MAX_WORD_LENGTH and\n",
        "            MIN_WORD_LENGTH <= len(hypothesis_tokens) <= MAX_WORD_LENGTH):\n",
        "            cleaned_premises.append(premise_tokens)\n",
        "            cleaned_hypotheses.append(hypothesis_tokens)\n",
        "            cleaned_labels.append(label)\n",
        "        # else: skip row\n",
        "\n",
        "    # Build DataFrame from all cleaned token lists\n",
        "    new_dataset = pd.DataFrame({\n",
        "        'premise': cleaned_premises,\n",
        "        'hypothesis': cleaned_hypotheses,\n",
        "        'label': cleaned_labels\n",
        "    })\n",
        "\n",
        "    return new_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Make the Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    [pluto, rotates, axis, every, [NUM], earth, da...\n",
              "1    [glenn, per, day, earth, rotates, axis, earth,...\n",
              "2    [geysers, periodic, gush, hot, water, surface,...\n",
              "3    [facts, liquid, water, droplets, changed, invi...\n",
              "4    [comparison, earth, rotates, axis, per, day, r...\n",
              "dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load raw data\n",
        "train_df = pd.read_json('Dataset/train.json')\n",
        "test_df = pd.read_json('Dataset/test.json')\n",
        "validation_df = pd.read_json('Dataset/validation.json')\n",
        "\n",
        "# Clean datasets. MAX_WORD_LENGTH set to 64 to remove very long texts\n",
        "clean_train_dataset = clean_dataset(train_df, MIN_WORD_LENGTH=3, MAX_WORD_LENGTH=64, stop_w=True, method=[], pos_filter=False)\n",
        "clean_test_dataset = clean_dataset(test_df, MIN_WORD_LENGTH=3, MAX_WORD_LENGTH=64,stop_w=True, method=[], pos_filter= False )\n",
        "clean_validation_dataset = clean_dataset(validation_df, MIN_WORD_LENGTH=3, MAX_WORD_LENGTH=64,stop_w=True, method=[], pos_filter= False )\n",
        "\n",
        "# Combine clean premises and hypotheses\n",
        "clean_t_dataset = clean_train_dataset['premise'] + clean_train_dataset['hypothesis']\n",
        "clean_t_dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocab size (including special tokens): 20842\n"
          ]
        }
      ],
      "source": [
        "# Create a unique word list from the cleaned dataset\n",
        "unique_words = set()\n",
        "for sentence in clean_t_dataset: # Both Premise and Hypothesis \n",
        "    for word in sentence:\n",
        "        unique_words.add(word)\n",
        "        \n",
        "unique_words_list = sorted(list(unique_words))\n",
        "\n",
        "# Make dictionary of words and indices\n",
        "word2id = {w:i for i,w in enumerate(unique_words_list)}\n",
        "id2word = {i:w for i,w in enumerate(unique_words_list)}\n",
        "\n",
        "\n",
        "# Add special tokens to use later\n",
        "SPECIAL_TOKENS = ['[PAD]','[UNK]','[CLS]','[SEP]'] # And [NUM] added during cleaning\n",
        "for tok in SPECIAL_TOKENS:\n",
        "    if tok not in word2id:\n",
        "        idx = len(word2id)\n",
        "        word2id[tok] = idx\n",
        "        id2word[idx] = tok\n",
        "\n",
        "VOCAB_SIZE = len(word2id)\n",
        "print(f\"Vocab size (including special tokens): {VOCAB_SIZE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_indexed_data(df, word2id, max_len):\n",
        "    input_ids = []\n",
        "    attention_mask = []\n",
        "    labels = []\n",
        "\n",
        "    label_map = {'neutral': 0, 'entails': 1}\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        premise_toks = row['premise']\n",
        "        hypothesis_toks = row['hypothesis']\n",
        "        label = row['label']\n",
        "\n",
        "        # Add special tokens \n",
        "        tokens = [word2id['[CLS]']] \\\n",
        "                + [word2id.get(w,word2id['[UNK]']) for w in premise_toks] \\\n",
        "                + [word2id['[SEP]']] \\\n",
        "                + [word2id.get(w,word2id['[UNK]']) for w in hypothesis_toks] \n",
        "        # Truncate\n",
        "        tokens = tokens[:max_len]\n",
        "\n",
        "        # Attention mask \n",
        "        attn = [1] * len(tokens)\n",
        "\n",
        "        # Pad\n",
        "        pad_len = max_len- len(tokens) # To fill the [PAD]\n",
        "        if pad_len > 0:\n",
        "            tokens += [word2id['[PAD]']] * pad_len\n",
        "            attn += [0] * pad_len # FLag positions as padding \n",
        "\n",
        "        input_ids.append(tokens)\n",
        "        attention_mask.append(attn)\n",
        "        labels.append(label_map[label])\n",
        "\n",
        "    return (torch.LongTensor(input_ids),\n",
        "            torch.LongTensor(attention_mask),\n",
        "            torch.LongTensor(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of x_train: torch.Size([22621, 64])\n",
            "Shape of train_masks: torch.Size([22621, 64])\n",
            "Shape of y_train: torch.Size([22621])\n",
            "\n",
            "--- Example ---\n",
            "First example real length (mask sum): 15\n",
            "First example PAD count: 49\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "MAX_SEQ_LEN = 64\n",
        "#embedding_size\n",
        "\n",
        "# Build train/test\n",
        "x_train, train_masks, y_train = prepare_indexed_data(clean_train_dataset, word2id, MAX_SEQ_LEN)\n",
        "x_test,  test_masks,  y_test  = prepare_indexed_data(clean_test_dataset,  word2id, MAX_SEQ_LEN)\n",
        "x_valid,  valid_masks,  y_valid  = prepare_indexed_data(clean_validation_dataset,  word2id, MAX_SEQ_LEN)\n",
        "\n",
        "print(\"Shape of x_train:\", x_train.shape)\n",
        "print(\"Shape of train_masks:\", train_masks.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "\n",
        "# Sanity Check \n",
        "i = 0\n",
        "print(\"\\n--- Example ---\")\n",
        "print(\"First example real length (mask sum):\", int(train_masks[i].sum()))\n",
        "print(\"First example PAD count:\", int((train_masks[i]==0).sum()))\n",
        "\n",
        "\n",
        "# Check we didn't cut off too much\n",
        "sns.histplot(np.sum(train_masks.numpy(), axis=1), bins = 16)\n",
        "plt.axvline(MAX_SEQ_LEN, color='red')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Prepare the datasets for model training\n",
        "train_ds = TensorDataset(x_train, train_masks, y_train)\n",
        "test_ds = TensorDataset(x_test, test_masks,y_test)\n",
        "valid_ds = TensorDataset(x_valid, valid_masks,y_valid)\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "# Dataloaders (shuffle for train)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1 Make an embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding matrix created with shape: (20842, 200)\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import FastText\n",
        "\n",
        "embedding_dim = 200\n",
        "\n",
        "fast_text_model = FastText(clean_t_dataset, # Both premise and Hypothesis \n",
        "                           vector_size=embedding_dim,\n",
        "                           window=3,\n",
        "                           sg=1,\n",
        "                           epochs=16\n",
        "                           )\n",
        "\n",
        "fast_text_model.wv.most_similar('saturn', topn=10)\n",
        "\n",
        "def build_embedding_matrix(word2id, pretrained_vectors, embedding_size):\n",
        "    vocab_size = len(word2id)\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_size), dtype=np.float32)\n",
        "\n",
        "    # Fill the matrix with pre-trained vectors\n",
        "    for word, idx in word2id.items():\n",
        "        if word == '[PAD]':\n",
        "            continue\n",
        "        try:\n",
        "            vec = pretrained_vectors[word]\n",
        "            if vec.shape[0] == embedding_size:\n",
        "                embedding_matrix[idx] = vec.astype(np.float32)\n",
        "            else:\n",
        "                # fallback if dims don’t match\n",
        "                embedding_matrix[idx] = np.random.normal(0.0, 0.02, size=(embedding_size,)).astype(np.float32)\n",
        "        except KeyError:\n",
        "            # special tokens or OOV start them with random values \n",
        "            embedding_matrix[idx] = np.random.normal(0.0, 0.02, size=(embedding_size,)).astype(np.float32)\n",
        "\n",
        "    print(\"Embedding matrix created with shape:\", embedding_matrix.shape)\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "\n",
        "embedding_matrix = build_embedding_matrix(word2id, fast_text_model.wv, embedding_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note we have collected following parameters from the pre-processing:\n",
        "- VOCAB_SIZE\n",
        "- MAX_SEQ_LEN\n",
        "- BATCH_SIZE\n",
        "- embedding_dim\n",
        "We have collected the objects:\n",
        "- embedding_matrix\n",
        "- fast_text_model\n",
        "- clean_train_dataset, clean_test_dataset, clean_validation_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for xb, mb, yb in loader:  # x, mask, y\n",
        "        xb, mb, yb = xb.to(device), mb.to(device), yb.to(device).long()\n",
        "        optimizer.zero_grad()\n",
        "        out = model(xb, mb)\n",
        "\n",
        "        # handle models that return (logits, ...) vs logits\n",
        "        logits = out[0] if isinstance(out, (tuple, list)) else out\n",
        "\n",
        "        loss = criterion(logits, yb)\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_size = yb.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_correct += (preds == yb).sum().item()\n",
        "        total += batch_size\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for xb, mb, yb in loader:\n",
        "        xb, mb, yb = xb.to(device), mb.to(device), yb.to(device).long()\n",
        "        out = model(xb, mb)\n",
        "        logits = out[0] if isinstance(out, (tuple, list)) else out\n",
        "\n",
        "        loss = criterion(logits, yb)\n",
        "        batch_size = yb.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        preds = logits.argmax(dim=1)\n",
        "        total_correct += (preds == yb).sum().item()\n",
        "        total += batch_size\n",
        "\n",
        "    return total_loss / total, total_correct / total\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, valid_loader, optimizer, n_epochs=10, patience=3):\n",
        "    best_val_acc = 0.0\n",
        "    epochs_no_improve = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, optimizer)\n",
        "        val_loss, val_acc = evaluate_model(model, valid_loader)\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs} - \"\n",
        "              f\"Train loss: {train_loss:.4f}, Train acc: {train_acc:.4f} - \"\n",
        "              f\"Val loss: {val_loss:.4f}, Val acc: {val_acc:.4f}\")\n",
        "\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            epochs_no_improve = 0\n",
        "            best_model_state = copy.deepcopy(model.state_dict())\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    if best_model_state is not None:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model A: RNN with Attention (placeholder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, hidden_dim=128, num_layers=2, dropout=0.3):\n",
        "        super(GRUModel, self).__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(VOCAB_SIZE, embedding_dim, padding_idx=0)\n",
        "        \n",
        "        self.gru_premise = nn.GRU(embedding_dim, hidden_dim, num_layers, \n",
        "                                 batch_first=True, bidirectional=True, dropout=dropout)\n",
        "\n",
        "        self.gru_hypothesis = nn.GRU(embedding_dim, hidden_dim, num_layers,\n",
        "                                    batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(hidden_dim * 4, hidden_dim),  # bidirectional * 2 for both premise and hypothesis\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, 2) # Output layer for 2 classes\n",
        "        )\n",
        "        \n",
        "    def forward(self, premise, hypothesis):\n",
        "        # Embedding\n",
        "        prem_embed = self.embedding(premise)\n",
        "        hyp_embed = self.embedding(hypothesis)\n",
        "        \n",
        "        # GRU encoding\n",
        "        prem_gru, _ = self.gru_premise(prem_embed)\n",
        "        hyp_gru, _ = self.gru_hypothesis(hyp_embed)\n",
        "        \n",
        "        # Pooling\n",
        "        prem_pooled = torch.mean(prem_gru, dim=1)\n",
        "        hyp_pooled = torch.mean(hyp_gru, dim=1)\n",
        "        \n",
        "        # Concatenate and classify\n",
        "        combined = torch.cat([prem_pooled, hyp_pooled], dim=1)\n",
        "        return self.classifier(combined), None  # Return None for attention weights for compatibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Train loss: 0.6244, Train acc: 0.6658 - Val loss: 0.7108, Val acc: 0.5819\n",
            "Epoch 2/10 - Train loss: 0.4619, Train acc: 0.7971 - Val loss: 0.7319, Val acc: 0.6118\n",
            "Epoch 3/10 - Train loss: 0.3828, Train acc: 0.8401 - Val loss: 0.7301, Val acc: 0.6172\n",
            "Epoch 4/10 - Train loss: 0.3173, Train acc: 0.8713 - Val loss: 0.8326, Val acc: 0.6672\n",
            "Epoch 5/10 - Train loss: 0.2548, Train acc: 0.9008 - Val loss: 0.8870, Val acc: 0.6441\n",
            "Epoch 6/10 - Train loss: 0.1893, Train acc: 0.9306 - Val loss: 1.0023, Val acc: 0.6633\n",
            "Epoch 7/10 - Train loss: 0.1319, Train acc: 0.9556 - Val loss: 1.1884, Val acc: 0.6618\n",
            "Early stopping triggered.\n"
          ]
        }
      ],
      "source": [
        "LR = 1e-3\n",
        "WD = 1e-2\n",
        "\n",
        "GRU_model = GRUModel(\n",
        "    hidden_dim=256,\n",
        "    num_layers=2,\n",
        "    dropout=0.3\n",
        ").to(device)\n",
        "\n",
        "optimizer = torch.optim.AdamW(GRU_model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "# train \n",
        "trained_GRU_model, history = train_model(GRU_model, train_loader, valid_loader, optimizer, n_epochs=10, patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare the losses of the two models\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history['train_loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model B: Transformer with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,d_model,max_len = 512, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0,max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0,d_model,2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:,0::2] = torch.sin(position * div_term) # For even dims\n",
        "        pe[:,1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = x + self.pe[:, :x.size(1), :] \n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, embedding_matrix, num_classes, n_heads, n_layers, dropout):\n",
        "        super().__init__()\n",
        "        vocab_size, embed_dim = embedding_matrix.shape\n",
        "        self.d_model = embed_dim\n",
        "\n",
        "        # Embedding Layer\n",
        "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=False, padding_idx=PAD_ID)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.pos_encoder = PositionalEncoding(embed_dim, max_len=MAX_SEQ_LEN, dropout=dropout)\n",
        "\n",
        "        # Transformer Encoder Layers\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=n_heads,\n",
        "            dropout=dropout,\n",
        "            dim_feedforward=256,\n",
        "            batch_first=True # Makes working with batch dimension easier\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer,num_layers=n_layers)\n",
        "\n",
        "        # Final Classification Head\n",
        "        self.classifier = nn.Linear(embed_dim,num_classes)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        padding_mask = (src_mask == 0)\n",
        "\n",
        "        # Apply embedding and positional encoding\n",
        "        embedded = self.embedding(src) * math.sqrt(self.d_model)\n",
        "        pos_encoded = self.pos_encoder(embedded)\n",
        "\n",
        "        # Pass trough the transformer encoder\n",
        "        encoded = self.transformer_encoder(pos_encoded,src_key_padding_mask = padding_mask)\n",
        "\n",
        "        # Use the output of the [CLS] token (first token) for classification\n",
        "        cls_output = encoded[:,0,:]\n",
        "\n",
        "        # Get final logits from the classifier\n",
        "        logits = self.classifier(cls_output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\NestedTensorImpl.cpp:182.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Train loss: 0.6689, Train acc: 0.6131 - Val loss: 0.8168, Val acc: 0.5442\n",
            "Epoch 2/10 - Train loss: 0.6349, Train acc: 0.6444 - Val loss: 0.7394, Val acc: 0.5711\n",
            "Epoch 3/10 - Train loss: 0.6168, Train acc: 0.6654 - Val loss: 0.7314, Val acc: 0.5980\n",
            "Epoch 4/10 - Train loss: 0.6036, Train acc: 0.6786 - Val loss: 0.7137, Val acc: 0.6188\n",
            "Epoch 5/10 - Train loss: 0.5907, Train acc: 0.6914 - Val loss: 0.7907, Val acc: 0.5949\n",
            "Epoch 6/10 - Train loss: 0.5815, Train acc: 0.7001 - Val loss: 0.7846, Val acc: 0.5872\n",
            "Epoch 7/10 - Train loss: 0.5733, Train acc: 0.7087 - Val loss: 0.8575, Val acc: 0.5796\n",
            "Early stopping triggered.\n"
          ]
        }
      ],
      "source": [
        "# Transformer Hyperparameters\n",
        "N_HEADS = 8\n",
        "N_LAYERS = 4\n",
        "DROPOUT = 0.5\n",
        "NUM_CLASSES = 2\n",
        "LR = 0.0002\n",
        "WD = 0.2\n",
        "NUM_EPOCHS = 50\n",
        "\n",
        "# Now, instantiate the model\n",
        "transformer_model = TransformerClassifier(\n",
        "    embedding_matrix=embedding_matrix,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    n_heads=N_HEADS,\n",
        "    n_layers=N_LAYERS,\n",
        "    dropout=DROPOUT\n",
        ")\n",
        "\n",
        "\n",
        "transformer_model.to(device)\n",
        "optimizer = torch.optim.AdamW(transformer_model.parameters(), lr = LR, weight_decay=WD)\n",
        "\n",
        "\n",
        "model, history = train_model(transformer_model, train_loader, valid_loader, optimizer, n_epochs=10, patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Compare the losses of the two models\n",
        "plt.figure(figsize=(5,3))\n",
        "plt.plot(history['train_loss'], label='Training Loss', color='blue')\n",
        "plt.plot(history['val_loss'], label='Validation Loss', color='orange')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model C: Encoder-Decoder with Attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_pair_data_from_df(df, word2id, max_len_prem, max_len_hyp):\n",
        "    PAD = word2id['[PAD]']\n",
        "    UNK = word2id['[UNK]']\n",
        "    label_map = {'neutral': 0, 'entails': 1}\n",
        "\n",
        "    prem_ids, prem_mask, hyp_ids, hyp_mask, labels = [], [], [], [], []\n",
        "    for _, row in df.iterrows():\n",
        "        p = [word2id.get(w, UNK) for w in row['premise']][:max_len_prem]\n",
        "        h = [word2id.get(w, UNK) for w in row['hypothesis']][:max_len_hyp]\n",
        "        pm = [1]*len(p); hm=[1]*len(h)\n",
        "        if len(p) < max_len_prem:\n",
        "            p += [PAD]*(max_len_prem-len(p)); pm += [0]*(max_len_prem-len(pm))\n",
        "        if len(h) < max_len_hyp:\n",
        "            h += [PAD]*(max_len_hyp-len(h)); hm += [0]*(max_len_hyp-len(hm))\n",
        "        prem_ids.append(p); prem_mask.append(pm)\n",
        "        hyp_ids.append(h);  hyp_mask.append(hm)\n",
        "        labels.append(label_map[row['label']])\n",
        "\n",
        "    return (torch.LongTensor(prem_ids),\n",
        "            torch.LongTensor(prem_mask),\n",
        "            torch.LongTensor(hyp_ids),\n",
        "            torch.LongTensor(hyp_mask),\n",
        "            torch.LongTensor(labels))\n",
        "\n",
        "xp_train, mp_train, xh_train, mh_train, _ = prepare_pair_data_from_df(clean_train_dataset, word2id, MAX_SEQ_LEN//2, MAX_SEQ_LEN//2)\n",
        "xp_test,  mp_test,  xh_test,  mh_test,  _ = prepare_pair_data_from_df(clean_test_dataset,  word2id, MAX_SEQ_LEN//2, MAX_SEQ_LEN//2)\n",
        "xp_valid,  mp_valid,  xh_valid,  mh_valid,  _ = prepare_pair_data_from_df(clean_validation_dataset,  word2id, MAX_SEQ_LEN//2, MAX_SEQ_LEN//2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AdditiveAttention(nn.Module):\n",
        "    def __init__(self, enc_dim, dec_dim, attn_dim):\n",
        "        super().__init__()\n",
        "        self.W_e = nn.Linear(enc_dim, attn_dim, bias=False)\n",
        "        self.W_d = nn.Linear(dec_dim, attn_dim, bias=False)\n",
        "        self.v   = nn.Linear(attn_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, enc_out, enc_mask, dec_state):\n",
        "        \"\"\"\n",
        "        enc_out: (B, T_enc, enc_dim)\n",
        "        enc_mask: (B, T_enc) with 1=real, 0=pad\n",
        "        dec_state: (B, dec_dim)\n",
        "        returns context (B, enc_dim) and attn weights (B, T_enc)\n",
        "        \"\"\"\n",
        "        B, T, H = enc_out.size()\n",
        "        # (B, T, attn_dim) + (B, 1, attn_dim) -> (B, T, attn_dim)\n",
        "        scores = self.v(torch.tanh(self.W_e(enc_out) + self.W_d(dec_state).unsqueeze(1))).squeeze(-1)  # (B, T)\n",
        "        # mask padded encoder positions\n",
        "        mask = (enc_mask == 0)\n",
        "        scores = scores.masked_fill(mask, -1e9)\n",
        "        alpha = torch.softmax(scores, dim=1)                         # (B, T)\n",
        "        ctx = torch.bmm(alpha.unsqueeze(1), enc_out).squeeze(1)      # (B, enc_dim)\n",
        "        return ctx, alpha\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, pad_idx, num_layers=1, dropout=0.1, bidir=True):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.gru = nn.GRU(emb_dim, hid_dim, num_layers=num_layers, batch_first=True,\n",
        "                          dropout=dropout if num_layers > 1 else 0.0, bidirectional=bidir)\n",
        "        self.bidir = bidir\n",
        "        self.hid_dim = hid_dim\n",
        "    def forward(self, x, mask):\n",
        "        # lengths for packing\n",
        "        lengths = mask.sum(dim=1).cpu()\n",
        "        emb = self.embedding(x)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths, batch_first=True, enforce_sorted=False)\n",
        "        packed_out, h = self.gru(packed)\n",
        "        out, _ = nn.utils.rnn.pad_packed_sequence(packed_out, batch_first=True)  # (B, T, H*dir)\n",
        "        return out, h\n",
        "\n",
        "    def output_dim(self):\n",
        "        return self.hid_dim * (2 if self.bidir else 1)\n",
        "\n",
        "\n",
        "class DecoderWithAttention(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim, hid_dim, pad_idx, enc_out_dim, attn_dim=128,\n",
        "                 num_layers=1, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_idx)\n",
        "        self.gru = nn.GRU(emb_dim + enc_out_dim, hid_dim, num_layers=num_layers,\n",
        "                          batch_first=True, dropout=dropout if num_layers>1 else 0.0)\n",
        "        self.attn = AdditiveAttention(enc_out_dim, hid_dim, attn_dim)\n",
        "        self.hid_dim = hid_dim\n",
        "\n",
        "    def forward(self, hyp_ids, hyp_mask, enc_out, enc_mask, h0=None):\n",
        "        \"\"\"\n",
        "        Run a single-pass decoder over the whole hypothesis with attention at each step.\n",
        "        Returns final hidden state and (optional) attention maps.\n",
        "        \"\"\"\n",
        "        B, Th = hyp_ids.size()\n",
        "        emb = self.embedding(hyp_ids)  # (B, Th, E)\n",
        "        # initialize hidden\n",
        "        if h0 is None:\n",
        "            h = torch.zeros(1, B, self.hid_dim, device=hyp_ids.device)\n",
        "        else:\n",
        "            h = h0\n",
        "        outputs = []\n",
        "        # step through time (simple & clear; fast enough for typical lengths)\n",
        "        for t in range(Th):\n",
        "            dec_state = h[-1]  # (B, H)\n",
        "            ctx, _ = self.attn(enc_out, enc_mask, dec_state)  # (B, enc_dim)\n",
        "            x_t = torch.cat([emb[:, t, :], ctx], dim=1).unsqueeze(1)  # (B,1,E+enc_dim)\n",
        "            out_t, h = self.gru(x_t, h)  # out_t: (B,1,H)\n",
        "            outputs.append(out_t)\n",
        "        dec_outputs = torch.cat(outputs, dim=1)  # (B, Th, H)\n",
        "\n",
        "        # take masked mean of decoder outputs as sequence representation\n",
        "        hyp_mask_float = hyp_mask.float().unsqueeze(-1)  # (B, Th, 1)\n",
        "        summed = (dec_outputs * hyp_mask_float).sum(dim=1)  # (B, H)\n",
        "        denom = hyp_mask_float.sum(dim=1).clamp_min(1.0)\n",
        "        pooled = summed / denom\n",
        "        return pooled, h\n",
        "\n",
        "class EncDecNLI(nn.Module):\n",
        "    def __init__(self, vocab_size, pad_idx, emb_dim=200,\n",
        "                 enc_hid=128, dec_hid=128, num_layers=1, dropout=0.1, bidir=True):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab_size, emb_dim, enc_hid, pad_idx, num_layers, dropout, bidir)\n",
        "        self.decoder = DecoderWithAttention(vocab_size, emb_dim, dec_hid, pad_idx,\n",
        "                                            enc_out_dim=self.encoder.output_dim(), attn_dim=128,\n",
        "                                            num_layers=1, dropout=dropout)\n",
        "        fusion_in = self.encoder.output_dim() + dec_hid\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(fusion_in, fusion_in),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(fusion_in, 1)  # binary logit\n",
        "        )\n",
        "\n",
        "    def forward(self, prem_ids, prem_mask, hyp_ids, hyp_mask):\n",
        "        enc_out, _ = self.encoder(prem_ids, prem_mask)                # (B, Tp, He)\n",
        "        hyp_repr, _ = self.decoder(hyp_ids, hyp_mask, enc_out, prem_mask)  # (B, Hd)\n",
        "        # mean-pool encoder outputs\n",
        "        prem_mask_f = prem_mask.float().unsqueeze(-1)\n",
        "        enc_pooled = (enc_out * prem_mask_f).sum(dim=1) / prem_mask_f.sum(dim=1).clamp_min(1.0)\n",
        "        fused = torch.cat([enc_pooled, hyp_repr], dim=1)\n",
        "        logit = self.classifier(fused).squeeze(1)  # (B,)\n",
        "        return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [],
      "source": [
        "def binary_accuracy_from_logits(logits, labels):\n",
        "    preds = (torch.sigmoid(logits) >= 0.5).long()\n",
        "    correct = (preds == labels.long()).sum().item()\n",
        "    return correct / labels.size(0)\n",
        "\n",
        "\n",
        "def train_model(model, train_loader, val_loader, device, optimizer=None, epochs=10, patience=3, clip=1.0):\n",
        "    if optimizer is None:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': []\n",
        "    }\n",
        "\n",
        "    best_val = float('inf')\n",
        "    best_state = None\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    model.to(device)\n",
        "    criterion.to(device)\n",
        "\n",
        "    for ep in range(1, epochs+1):\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        tot_loss, tot_correct, tot_count = 0.0, 0, 0\n",
        "        for prem_ids, prem_mask, hyp_ids, hyp_mask, labels in train_loader:\n",
        "            prem_ids = prem_ids.to(device)\n",
        "            prem_mask = prem_mask.to(device)\n",
        "            hyp_ids = hyp_ids.to(device)\n",
        "            hyp_mask = hyp_mask.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(prem_ids, prem_mask, hyp_ids, hyp_mask)\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            if clip is not None:\n",
        "                nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "\n",
        "            tot_loss += loss.item() * labels.size(0)\n",
        "            tot_correct += (torch.sigmoid(logits).round().long() == labels.long()).sum().item()\n",
        "            tot_count += labels.size(0)\n",
        "\n",
        "        train_loss = tot_loss / tot_count\n",
        "        train_acc = tot_correct / tot_count\n",
        "\n",
        "        # ---- eval ----\n",
        "        model.eval()\n",
        "        v_loss, v_correct, v_count = 0.0, 0, 0\n",
        "        with torch.no_grad():\n",
        "            for prem_ids, prem_mask, hyp_ids, hyp_mask, labels in val_loader:\n",
        "                prem_ids = prem_ids.to(device)\n",
        "                prem_mask = prem_mask.to(device)\n",
        "                hyp_ids = hyp_ids.to(device)\n",
        "                hyp_mask = hyp_mask.to(device)\n",
        "                labels_f = labels.float().to(device)\n",
        "\n",
        "                logits = model(prem_ids, prem_mask, hyp_ids, hyp_mask)\n",
        "                loss = criterion(logits, labels_f)\n",
        "\n",
        "                v_loss += loss.item() * labels.size(0)\n",
        "                v_correct += (torch.sigmoid(logits).round().long() == labels.long().to(device)).sum().item()\n",
        "                v_count += labels.size(0)\n",
        "\n",
        "        val_loss = v_loss / v_count\n",
        "        val_acc = v_correct / v_count\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {ep:02d} | train loss {train_loss:.4f} acc {train_acc:.4f} | \"\n",
        "              f\"val loss {val_loss:.4f} acc {val_acc:.4f}\")\n",
        "\n",
        "        # early stopping\n",
        "        if val_loss < best_val - 1e-6:\n",
        "            best_val = val_loss\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping at epoch {ep} (no improvement for {patience} epochs).\")\n",
        "                break\n",
        "\n",
        "    # load best\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state)\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (32) must match the size of tensor b (24) at non-singleton dimension 1",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[105], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR, weight_decay\u001b[38;5;241m=\u001b[39mWD)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train for 10 epochs with early stopping\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                             \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHistory:\u001b[39m\u001b[38;5;124m\"\u001b[39m, history)\n",
            "Cell \u001b[1;32mIn[99], line 36\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, device, optimizer, epochs, patience, clip)\u001b[0m\n\u001b[0;32m     33\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     35\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 36\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprem_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprem_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyp_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyp_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[0;32m     38\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
            "File \u001b[1;32mc:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[98], line 104\u001b[0m, in \u001b[0;36mEncDecNLI.forward\u001b[1;34m(self, prem_ids, prem_mask, hyp_ids, hyp_mask)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, prem_ids, prem_mask, hyp_ids, hyp_mask):\n\u001b[0;32m    103\u001b[0m     enc_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(prem_ids, prem_mask)                \u001b[38;5;66;03m# (B, Tp, He)\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     hyp_repr, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhyp_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyp_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprem_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, Hd)\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;66;03m# mean-pool encoder outputs\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     prem_mask_f \u001b[38;5;241m=\u001b[39m prem_mask\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[98], line 73\u001b[0m, in \u001b[0;36mDecoderWithAttention.forward\u001b[1;34m(self, hyp_ids, hyp_mask, enc_out, enc_mask, h0)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Th):\n\u001b[0;32m     72\u001b[0m     dec_state \u001b[38;5;241m=\u001b[39m h[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# (B, H)\u001b[39;00m\n\u001b[1;32m---> 73\u001b[0m     ctx, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_state\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (B, enc_dim)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m     x_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([emb[:, t, :], ctx], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# (B,1,E+enc_dim)\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     out_t, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgru(x_t, h)  \u001b[38;5;66;03m# out_t: (B,1,H)\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Josh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "Cell \u001b[1;32mIn[98], line 20\u001b[0m, in \u001b[0;36mAdditiveAttention.forward\u001b[1;34m(self, enc_out, enc_mask, dec_state)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# mask padded encoder positions\u001b[39;00m\n\u001b[0;32m     19\u001b[0m mask \u001b[38;5;241m=\u001b[39m (enc_mask \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mscores\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasked_fill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1e9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m alpha \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(scores, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)                         \u001b[38;5;66;03m# (B, T)\u001b[39;00m\n\u001b[0;32m     22\u001b[0m ctx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(alpha\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), enc_out)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)      \u001b[38;5;66;03m# (B, enc_dim)\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (24) at non-singleton dimension 1"
          ]
        }
      ],
      "source": [
        "# Build loaders\n",
        "train_ds = TensorDataset(xp_train, mp_train, xh_train, mh_train, y_train)\n",
        "valid_ds = TensorDataset(xp_valid,  mp_valid,  xh_valid,  mh_valid, y_valid)\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "vocab_size = len(word2id)\n",
        "pad_idx = word2id['[PAD]']\n",
        "model = EncDecNLI(vocab_size=vocab_size, pad_idx=pad_idx,\n",
        "                  emb_dim=200, enc_hid=128, dec_hid=128, dropout=0.2, bidir=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "# Train for 10 epochs with early stopping\n",
        "model, history = train_model(model, train_loader, val_loader, device, optimizer=optimizer, epochs=10, patience=3, clip=1.0)\n",
        "\n",
        "print(\"History:\", history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO cleanup encoder-decoder\n",
        "# TODO hyperparameter optimisation (additional ablation study)\n",
        "# TODO Attention ablation study\n",
        "# TODO final model evaluations and comparison\n",
        "# TODO qualitative analysis of attention"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
