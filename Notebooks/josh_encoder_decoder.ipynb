{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2025 CITS4012 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Josh\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "import pprint\n",
        "\n",
        "# For data processing\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# For implementing the word2vec family of algorithms\n",
        "from gensim.models import FastText, KeyedVectors\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.Dataset Processing\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.1. Basic preparation: create desired format of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qvff21Hv8zjk"
      },
      "outputs": [],
      "source": [
        "# Load datasets\n",
        "train_raw = json.load(open('train.json'))\n",
        "val_raw = json.load(open('validation.json'))\n",
        "test_raw = json.load(open('test.json'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common English contractions.\n",
        "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\",\n",
        "                    \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\",\n",
        "                    \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
        "                    \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\",\n",
        "                    \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n",
        "                    \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
        "                    \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\",\n",
        "                    \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\",\n",
        "                    \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\n",
        "                    \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
        "                    \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\",\n",
        "                    \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\n",
        "                    \"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
        "                    \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
        "                    \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\",\n",
        "                    \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
        "                    \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\",\n",
        "                    \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\",\n",
        "                    \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\",\n",
        "                    \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\",\n",
        "                    \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
        "                    \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
        "\n",
        "# Preprocess a list of sentences\n",
        "def pre_process(sent_list):\n",
        "    output = []\n",
        "    for sent in sent_list:\n",
        "        sent = sent.lower() #case-folding\n",
        "        for word, new_word in contraction_dict.items():\n",
        "            sent = sent.replace(word, new_word) #dealing with contractions\n",
        "        sent = re.sub(r'[^\\w\\s]','',sent) #removing punctuation\n",
        "        output.append(word_tokenize(sent)) #tokenization\n",
        "    return output\n",
        "\n",
        "def pre_process_datasets(dataset):\n",
        "    raw_premises = []\n",
        "    raw_hypotheses = []\n",
        "    labels = []\n",
        "    label_keys = []\n",
        "    keys_as_integers = []\n",
        "    for key, value in dataset['label'].items():\n",
        "        labels.append(value)\n",
        "        label_keys.append(key)\n",
        "        keys_as_integers.append(int(key))\n",
        "    raw_premises = [dataset['premise'][key] for key in label_keys]\n",
        "    raw_hypotheses = [dataset['hypothesis'][key] for key in label_keys]\n",
        "    processed_premises = pre_process(raw_premises)\n",
        "    processed_hypotheses = pre_process(raw_hypotheses)\n",
        "    return processed_premises, processed_hypotheses, labels, keys_as_integers\n",
        "        \n",
        "        \n",
        "# Preprocessing the training using the functions defined above\n",
        "all_train_premises, all_train_hypotheses, all_train_labels, all_train_keyints = pre_process_datasets(train_raw)\n",
        "\n",
        "# setup vocab to index dictionary\n",
        "word_to_ix = {\"<PAD>\": 0, \"<OOV>\": 1}\n",
        "for sentence in all_train_premises+all_train_hypotheses:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert tokenized sentences to index lists\n",
        "def to_index(data, to_ix, padlength=None):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] if w in to_ix else to_ix[\"<OOV>\"] for w in sent])\n",
        "    if padlength is not None:\n",
        "        for i in range(len(input_index_list)):\n",
        "            if len(input_index_list[i]) < padlength:\n",
        "                input_index_list[i] = input_index_list[i] + [to_ix[\"<PAD>\"]] * (padlength - len(input_index_list[i]))\n",
        "    return input_index_list\n",
        "\n",
        "def make_idx_data(data_raw, padlength=None):\n",
        "    premises, hypotheses, labels, keyints = pre_process_datasets(data_raw)\n",
        "    premises_idx = to_index(premises, word_to_ix, padlength)\n",
        "    hypotheses_idx = to_index(hypotheses, word_to_ix, padlength)\n",
        "    binary_labels = np.array([1 if label == 'entails' else 0 for label in labels])\n",
        "    return premises_idx, hypotheses_idx, binary_labels, keyints\n",
        "\n",
        "all_train_premises_idx, all_train_hypotheses_idx, all_y_train, _ = make_idx_data(train_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " ***Before Processing***\n",
            "By combining an up-to-date child I.D. card and the DNA I.D. Kit, parents can have a valuable child identification system.\n",
            "Children resemble their parents because they have similar dna.\n",
            "neutral\n",
            "\n",
            " ***After Processing***\n",
            "['by', 'combining', 'an', 'uptodate', 'child', 'id', 'card', 'and', 'the', 'dna', 'id', 'kit', 'parents', 'can', 'have', 'a', 'valuable', 'child', 'identification', 'system']\n",
            "['children', 'resemble', 'their', 'parents', 'because', 'they', 'have', 'similar', 'dna']\n",
            "neutral\n",
            "\n",
            " ***After Indexation***\n",
            "[39, 750, 285, 751, 425, 752, 753, 41, 15, 416, 752, 754, 420, 28, 67, 35, 755, 425, 756, 74]\n",
            "[99, 1078, 271, 420, 1138, 97, 67, 473, 416]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Example processing\n",
        "i = '100'\n",
        "print(\"\\n ***Before Processing***\")\n",
        "print(train_raw['premise'][i])\n",
        "print(train_raw['hypothesis'][i])\n",
        "print(train_raw['label'][i])\n",
        "print(\"\\n ***After Processing***\")\n",
        "print(all_train_premises[int(i)])\n",
        "print(all_train_hypotheses[int(i)])\n",
        "print(all_train_labels[int(i)])\n",
        "print(\"\\n ***After Indexation***\")\n",
        "print(all_train_premises_idx[int(i)])\n",
        "print(all_train_hypotheses_idx[int(i)])\n",
        "print(all_y_train[int(i)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2. Clean dataset: remove pathalogical instances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum sentence length: 10563\n",
            "Minimum sentence length: 0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create combined premise/hypothesis list from the training set to examine\n",
        "all_train_sentences = all_train_premises + all_train_hypotheses\n",
        "\n",
        "lengths = np.array([len(sent) for sent in all_train_sentences])\n",
        "print(f'Maximum sentence length: {lengths.max()}')\n",
        "print(f'Minimum sentence length: {lengths.min()}')\n",
        "\n",
        "sns.histplot(lengths[lengths < 60])\n",
        "plt.title('Sentence Lengths in Training Set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make the final datasets, only allowing sentences up to maxlength long and padding to this maxlength\n",
        "maxlength = 60\n",
        "\n",
        "def make_final_datasets(train_raw, maxlength=maxlength):\n",
        "    premises, hypotheses, labels, keys = make_idx_data(train_raw, padlength=maxlength)\n",
        "    cleaned_premises = []\n",
        "    cleaned_hypotheses = []\n",
        "    cleaned_labels = []\n",
        "    cleaned_keys = []\n",
        "    for i in keys:\n",
        "        if len(premises[i]) >= 3 and len(premises[i]) <= maxlength and len(hypotheses[i]) >= 3 and len(hypotheses[i]) <= maxlength:\n",
        "            cleaned_premises.append(premises[i])\n",
        "            cleaned_hypotheses.append(hypotheses[i])\n",
        "            cleaned_labels.append(labels[i])\n",
        "            cleaned_keys.append(i)\n",
        "    return np.array(cleaned_premises, dtype=np.int64), np.array(cleaned_hypotheses, dtype=np.int64), np.array(cleaned_labels, dtype=np.int64), cleaned_keys\n",
        "\n",
        "\n",
        "train_premises, train_hypotheses, y_train, clean_train_keyints = make_final_datasets(train_raw)\n",
        "val_premises, val_hypotheses, y_val, clean_val_keyints = make_final_datasets(val_raw)\n",
        "test_premises, test_hypotheses, y_test, clean_test_keyints = make_final_datasets(test_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "QIEqDDT78q39"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dec_dim, enc_dim, attn_dim=None):\n",
        "        super().__init__()\n",
        "        if attn_dim is None:\n",
        "            attn_dim = dec_dim\n",
        "        # input to attention = [dec_hidden (dec_dim) ; enc_output (enc_dim)]\n",
        "        self.attn = nn.Linear(dec_dim + enc_dim, attn_dim)\n",
        "        self.v = nn.Linear(attn_dim, 1, bias=False)\n",
        "\n",
        "    def forward(self, decoder_hidden, encoder_outputs):\n",
        "        \"\"\"\n",
        "        decoder_hidden: [batch, dec_dim]\n",
        "        encoder_outputs: [batch, src_len, enc_dim]\n",
        "        \"\"\"\n",
        "        B, T, E = encoder_outputs.size()          # enc_dim = E\n",
        "        # repeat decoder hidden across time\n",
        "        hidden_rep = decoder_hidden.unsqueeze(1).expand(B, T, decoder_hidden.size(1))  # [B, T, dec_dim]\n",
        "        energy = torch.tanh(self.attn(torch.cat([hidden_rep, encoder_outputs], dim=2)))  # [B, T, attn_dim]\n",
        "        scores = self.v(energy).squeeze(2)        # [B, T]\n",
        "        alpha = F.softmax(scores, dim=1)          # [B, T]\n",
        "        return alpha\n",
        "\n",
        "class NLIModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "\n",
        "        # Encoder: bidirectional. Output dim = 2H\n",
        "        self.encoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Decoder: unidirectional. Hidden dim = H\n",
        "        self.decoder = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "\n",
        "        # Attention over encoder (enc_dim=2H) using decoder state (dec_dim=H)\n",
        "        self.attention = Attention(dec_dim=hidden_dim, enc_dim=hidden_dim * 2, attn_dim=hidden_dim)\n",
        "\n",
        "        # Final classifier gets [dec_hidden (H) ; context (2H)] = 3H\n",
        "        self.fc = nn.Linear(hidden_dim * 3, num_classes)\n",
        "\n",
        "    def forward(self, premise, hypothesis):\n",
        "        # Encode premise\n",
        "        prem_emb = self.embedding(premise)                      # [B, T_p, E]\n",
        "        enc_outs, _ = self.encoder(prem_emb)                    # [B, T_p, 2H]\n",
        "\n",
        "        # Decode hypothesis (we just use final hidden for classification)\n",
        "        hypo_emb = self.embedding(hypothesis)                   # [B, T_h, E]\n",
        "        dec_outs, (h, c) = self.decoder(hypo_emb)               # h: [1, B, H]\n",
        "        dec_hidden = h[-1]                                      # [B, H]\n",
        "\n",
        "        # Attention over encoder outputs using decoder final state\n",
        "        attn_w = self.attention(dec_hidden, enc_outs)           # [B, T_p]\n",
        "        context = torch.bmm(attn_w.unsqueeze(1), enc_outs).squeeze(1)  # [B, 2H]\n",
        "\n",
        "        # Concatenate decoder hidden and context\n",
        "        combined = torch.cat([dec_hidden, context], dim=1)      # [B, 3H]\n",
        "\n",
        "        logits = self.fc(combined)                              # [B, num_classes]\n",
        "        return F.log_softmax(logits, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11692\\2120145448.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_premises   = torch.tensor(train_premises, dtype=torch.long)\n",
            "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11692\\2120145448.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_hypotheses = torch.tensor(train_hypotheses, dtype=torch.long)\n",
            "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11692\\2120145448.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_train          = torch.tensor(y_train, dtype=torch.long)\n",
            "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11692\\2120145448.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_premises     = torch.tensor(val_premises, dtype=torch.long)\n",
            "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11692\\2120145448.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_hypotheses   = torch.tensor(val_hypotheses, dtype=torch.long)\n",
            "C:\\Users\\Josh\\AppData\\Local\\Temp\\ipykernel_11692\\2120145448.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  y_val            = torch.tensor(y_val, dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# Convert numpy arrays to torch tensors\n",
        "train_premises   = torch.tensor(train_premises, dtype=torch.long)\n",
        "train_hypotheses = torch.tensor(train_hypotheses, dtype=torch.long)\n",
        "y_train          = torch.tensor(y_train, dtype=torch.long)\n",
        "\n",
        "val_premises     = torch.tensor(val_premises, dtype=torch.long)\n",
        "val_hypotheses   = torch.tensor(val_hypotheses, dtype=torch.long)\n",
        "y_val            = torch.tensor(y_val, dtype=torch.long)\n",
        "\n",
        "# Create datasets\n",
        "train_ds = TensorDataset(train_premises, train_hypotheses, y_train)\n",
        "val_ds   = TensorDataset(val_premises, val_hypotheses, y_val)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss=0.553, Train Acc=0.714, Val Loss=0.573, Val Acc=0.687\n",
            "Epoch 2: Train Loss=0.416, Train Acc=0.809, Val Loss=0.581, Val Acc=0.708\n",
            "Epoch 3: Train Loss=0.305, Train Acc=0.869, Val Loss=0.626, Val Acc=0.713\n",
            "Epoch 4: Train Loss=0.193, Train Acc=0.924, Val Loss=0.757, Val Acc=0.708\n",
            "Epoch 5: Train Loss=0.108, Train Acc=0.962, Val Loss=1.086, Val Acc=0.692\n"
          ]
        }
      ],
      "source": [
        "# ==== Model, loss, optimizer ====\n",
        "vocab_size = len(word_to_ix)\n",
        "embed_dim = 100\n",
        "hidden_dim = 128\n",
        "num_classes = 2\n",
        "\n",
        "model = NLIModel(vocab_size, embed_dim, hidden_dim, num_classes)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "# ==== Training & Evaluation Loop ====\n",
        "def accuracy(preds, labels):\n",
        "    return (preds.argmax(dim=1) == labels).float().mean().item()\n",
        "\n",
        "for epoch in range(5):  # small number of epochs for demo\n",
        "    model.train()\n",
        "    train_loss, train_acc = 0, 0\n",
        "    for premise, hypo, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(premise, hypo)\n",
        "        loss = criterion(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        train_acc += accuracy(output, labels)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, val_acc = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for premise, hypo, labels in val_loader:\n",
        "            output = model(premise, hypo)\n",
        "            loss = criterion(output, labels)\n",
        "            val_loss += loss.item()\n",
        "            val_acc += accuracy(output, labels)\n",
        "\n",
        "    # Average across batches\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc /= len(train_loader)\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc /= len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: \"\n",
        "          f\"Train Loss={train_loss:.3f}, Train Acc={train_acc:.3f}, \"\n",
        "          f\"Val Loss={val_loss:.3f}, Val Acc={val_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
